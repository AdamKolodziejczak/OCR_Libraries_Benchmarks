{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numpy version: 1.4.2\n"
     ]
    }
   ],
   "source": [
    "##%pip install kagglehub\n",
    "#%pip uninstall -y tensorflow tensorflow-cpu tensorflow-gpu keras-ocr numpy protobuf\n",
    "#%pip cache purge\n",
    "#\n",
    "#%pip install \"numpy<2\" --upgrade\n",
    "#\n",
    "## Install specific versions with --no-deps to prevent auto-upgrades\n",
    "#%pip install tensorflow==2.10.0\n",
    "#%pip install keras-ocr==0.8.9\n",
    "#%pip install tensorflow-gpu==2.10.0 --no-deps\n",
    "#%pip install tensorflow-cpu==2.10.0 --no-deps\n",
    "#%pip install tensorflow==2.10.0 --no-deps\n",
    "#%pip install protobuf==3.20.3 --no-deps\n",
    "#%pip install python-Levenshtein\n",
    "#%pip install pytesseract\n",
    "#%pip install easyocr\n",
    "#%pip install git+https://github.com/faustomorales/keras-ocr.git@v0.8.9\n",
    "import kagglehub\n",
    "from kagglehub import KaggleDatasetAdapter\n",
    "import pandas as pd\n",
    "print(\"Numpy version:\", pd.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adam4\\AppData\\Local\\Temp\\ipykernel_15200\\2912609907.py:5: DeprecationWarning: load_dataset is deprecated and will be removed in future version.\n",
      "  df = kagglehub.load_dataset(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 5 records:         FILENAME  IDENTITY\n",
      "0  TEST_0001.jpg     KEVIN\n",
      "1  TEST_0002.jpg  CLOTAIRE\n",
      "2  TEST_0003.jpg      LENA\n",
      "3  TEST_0004.jpg     JULES\n",
      "4  TEST_0005.jpg   CHERPIN\n"
     ]
    }
   ],
   "source": [
    "# Example\n",
    "file_path = \"written_name_test_v2.csv\"\n",
    "\n",
    "# Load the latest version\n",
    "df = kagglehub.load_dataset(\n",
    "  KaggleDatasetAdapter.PANDAS,\n",
    "  \"landlord/handwriting-recognition\",\n",
    "  file_path,\n",
    "  # Provide any additional arguments like \n",
    "  # sql_query or pandas_kwargs. See the \n",
    "  # documenation for more information:\n",
    "  # https://github.com/Kaggle/kagglehub/blob/main/README.md#kaggledatasetadapterpandas\n",
    ")\n",
    "\n",
    "print(\"First 5 records:\", df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path to dataset files: C:\\Users\\adam4\\.cache\\kagglehub\\datasets\\landlord\\handwriting-recognition\\versions\\1\n"
     ]
    }
   ],
   "source": [
    "import kagglehub\n",
    "\n",
    "# Download latest version\n",
    "path = kagglehub.dataset_download(\"landlord/handwriting-recognition\")\n",
    "\n",
    "print(\"Path to dataset files:\", path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FILENAME</th>\n",
       "      <th>IDENTITY</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TEST_0001.jpg</td>\n",
       "      <td>KEVIN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TEST_0002.jpg</td>\n",
       "      <td>CLOTAIRE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TEST_0003.jpg</td>\n",
       "      <td>LENA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TEST_0004.jpg</td>\n",
       "      <td>JULES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TEST_0005.jpg</td>\n",
       "      <td>CHERPIN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41365</th>\n",
       "      <td>TEST_41366.jpg</td>\n",
       "      <td>ALEXANE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41366</th>\n",
       "      <td>TEST_41367.jpg</td>\n",
       "      <td>PEREIRA-SILVA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41367</th>\n",
       "      <td>TEST_41368.jpg</td>\n",
       "      <td>LAURENT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41368</th>\n",
       "      <td>TEST_41369.jpg</td>\n",
       "      <td>DEFFENSE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41369</th>\n",
       "      <td>TEST_41370.jpg</td>\n",
       "      <td>MELAB</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>41370 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             FILENAME       IDENTITY\n",
       "0       TEST_0001.jpg          KEVIN\n",
       "1       TEST_0002.jpg       CLOTAIRE\n",
       "2       TEST_0003.jpg           LENA\n",
       "3       TEST_0004.jpg          JULES\n",
       "4       TEST_0005.jpg        CHERPIN\n",
       "...               ...            ...\n",
       "41365  TEST_41366.jpg        ALEXANE\n",
       "41366  TEST_41367.jpg  PEREIRA-SILVA\n",
       "41367  TEST_41368.jpg        LAURENT\n",
       "41368  TEST_41369.jpg       DEFFENSE\n",
       "41369  TEST_41370.jpg          MELAB\n",
       "\n",
       "[41370 rows x 2 columns]"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv('1/written_name_train_v2.csv')\n",
    "valid = pd.read_csv('1/written_name_validation_v2.csv')\n",
    "test = pd.read_csv('1/written_name_test_v2.csv')\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of NaNs in train set      :  565\n",
      "Number of NaNs in validation set :  78\n",
      "Number of NaNs in test set :  70\n",
      "Number of NaNs in train set      :  0\n",
      "Number of NaNs in validation set :  0\n",
      "Number of NaNs in test set :  0\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of NaNs in train set      : \", train['IDENTITY'].isnull().sum())\n",
    "print(\"Number of NaNs in validation set : \", valid['IDENTITY'].isnull().sum())\n",
    "print(\"Number of NaNs in test set : \", test['IDENTITY'].isnull().sum())\n",
    "\n",
    "train.dropna(axis=0, inplace=True)\n",
    "valid.dropna(axis=0, inplace=True)\n",
    "test.dropna(axis=0, inplace=True)\n",
    "print(\"Number of NaNs in train set      : \", train['IDENTITY'].isnull().sum())\n",
    "print(\"Number of NaNs in validation set : \", valid['IDENTITY'].isnull().sum())\n",
    "print(\"Number of NaNs in test set : \", test['IDENTITY'].isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "unreadable = train[train['IDENTITY'] == 'UNREADABLE']\n",
    "unreadable.reset_index(inplace = True, drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adam4\\AppData\\Local\\Temp\\ipykernel_15200\\2570346784.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test['IDENTITY'] = test['IDENTITY'].str.upper()\n"
     ]
    }
   ],
   "source": [
    "train = train[train[\"IDENTITY\"] != 'UNREADABLE']\n",
    "valid = valid[valid[\"IDENTITY\"] != \"UNREADABLE\"]\n",
    "test = test[test[\"IDENTITY\"] != \"UNREADABLE\"]\n",
    "train['IDENTITY'] = train['IDENTITY'].str.upper()\n",
    "valid['IDENTITY'] = valid['IDENTITY'].str.upper()\n",
    "test['IDENTITY'] = test['IDENTITY'].str.upper()\n",
    "train.reset_index(inplace=True, drop=True)\n",
    "valid.reset_index(inplace=True, drop=True)\n",
    "test.reset_index(inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FILENAME</th>\n",
       "      <th>IDENTITY</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TEST_0001.jpg</td>\n",
       "      <td>KEVIN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TEST_0002.jpg</td>\n",
       "      <td>CLOTAIRE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TEST_0003.jpg</td>\n",
       "      <td>LENA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TEST_0004.jpg</td>\n",
       "      <td>JULES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TEST_0005.jpg</td>\n",
       "      <td>CHERPIN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41284</th>\n",
       "      <td>TEST_41366.jpg</td>\n",
       "      <td>ALEXANE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41285</th>\n",
       "      <td>TEST_41367.jpg</td>\n",
       "      <td>PEREIRA-SILVA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41286</th>\n",
       "      <td>TEST_41368.jpg</td>\n",
       "      <td>LAURENT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41287</th>\n",
       "      <td>TEST_41369.jpg</td>\n",
       "      <td>DEFFENSE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41288</th>\n",
       "      <td>TEST_41370.jpg</td>\n",
       "      <td>MELAB</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>41289 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             FILENAME       IDENTITY\n",
       "0       TEST_0001.jpg          KEVIN\n",
       "1       TEST_0002.jpg       CLOTAIRE\n",
       "2       TEST_0003.jpg           LENA\n",
       "3       TEST_0004.jpg          JULES\n",
       "4       TEST_0005.jpg        CHERPIN\n",
       "...               ...            ...\n",
       "41284  TEST_41366.jpg        ALEXANE\n",
       "41285  TEST_41367.jpg  PEREIRA-SILVA\n",
       "41286  TEST_41368.jpg        LAURENT\n",
       "41287  TEST_41369.jpg       DEFFENSE\n",
       "41288  TEST_41370.jpg          MELAB\n",
       "\n",
       "[41289 rows x 2 columns]"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from difflib import SequenceMatcher\n",
    "import Levenshtein\n",
    "import cv2\n",
    "import time\n",
    "import numpy as np\n",
    "\n",
    "# Directories\n",
    "expected_output_directory = 'cleaned/000'\n",
    "actual_output_directory = 'outputs/py_cleaned'\n",
    "trainSize = 25000\n",
    "validateSize = 2500\n",
    "\n",
    "#width =256 and height= 64\n",
    "def cleanImage(img):\n",
    "    (h,w) = img.shape\n",
    "    final = np.ones([64,256])*255 #blank\n",
    "    if w>256:\n",
    "         img = img[:,:256]     #MAYBE TRY RESIZE HERE\n",
    "    if h>64:\n",
    "        img=img[:64, :]\n",
    "\n",
    "    final[:h, :w]=img\n",
    "    final = cv2.rotate(final,cv2.ROTATE_90_CLOCKWISE)\n",
    "    return final\n",
    "\n",
    "def cleanTextFile(text):\n",
    "    return text.replace('\\n', ' ')\n",
    "    \n",
    "# METHOD 1:\n",
    "# Similarity percentage using Levenshtein distance (edit distance), more robust for OCR\n",
    "# Levenshtein distance outputs how similar, not dis-similar\n",
    "def calculate_similarity_lev(text1, text2):\n",
    "    text1 = cleanTextFile(text1)\n",
    "    text2 = cleanTextFile(text2)\n",
    "    print(f\"Text1: {text1}\")\n",
    "    print(f\"Text2: {text2}\")\n",
    "    \n",
    "    distance = Levenshtein.distance(text1, text2)\n",
    "    max_length = max(len(text1), len(text2))\n",
    "    if max_length == 0:  # Avoids dividing by zero\n",
    "        return 100.0\n",
    "    return (1 - distance / max_length) * 100\n",
    "\n",
    "def openCalculate(path):\n",
    "    result = ''\n",
    "    if os.path.exists(path):\n",
    "                with open(path, 'r') as f:\n",
    "                    result = f.read()\n",
    "    return result\n",
    "\n",
    "def prepTrainValid(type, size):\n",
    "    for i in range(size):\n",
    "        path =''\n",
    "        if type == \"train\":\n",
    "            path = \"1/train_v2/train/\"+train.loc[i, \"FILENAME\"]\n",
    "        elif type ==\"validation\":\n",
    "            path = \"1/validation_v2/validation/\"+valid.loc[i, \"FILENAME\"]\n",
    "        else:\n",
    "             print(\"Wrong type\")\n",
    "        img = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n",
    "        img = cleanImage(img)\n",
    "        img = img/255 #Normalization\n",
    "        return np.array(img).reshape(-1,256,64,1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadDataAll(groundTruthDir, pyTesseractOutputTyped, pyTesseractOutputWritten, \n",
    "                kerasOCROutputTyped, kerasOCROutputWritten, easyOCROutputTyped, easyOCROutputWritten):\n",
    "    count = 0\n",
    "    pyTesseractTypedScore = 0\n",
    "    pyTesseractWrittenScore = 0\n",
    "    kerasOCRTypedScore = 0\n",
    "    kerasOCRWrittenScore = 0\n",
    "    easyOCRTypedScore = 0\n",
    "    easyOCRWrittenScore = 0\n",
    "\n",
    "    for filename in os.listdir(groundTruthDir):\n",
    "        if filename.endswith('.txt'):\n",
    "            # Construct file paths\n",
    "            groundTruthPath = os.path.join(groundTruthDir, filename)\n",
    "            pyTesseractTypedPath = os.path.join(pyTesseractOutputTyped, filename)\n",
    "            pyTesseractWrittenPath = os.path.join(pyTesseractOutputWritten, filename)\n",
    "            kerasOCRTypedPath = os.path.join(kerasOCROutputTyped, filename)\n",
    "            kerasOCRWrittenPath = os.path.join(kerasOCROutputWritten, filename)\n",
    "            easyOCRTypedPath = os.path.join(easyOCROutputTyped, filename)\n",
    "            easyOCRWrittenPath = os.path.join(easyOCROutputWritten, filename)\n",
    "    \n",
    "            # Read file contents\n",
    "            groundTruthText = openCalculate(groundTruthPath)\n",
    "            pyTesseractTypedText = openCalculate(pyTesseractTypedPath)\n",
    "            pyTesseractWrittenText = openCalculate(pyTesseractWrittenPath)\n",
    "            kerasOCRTypedText = openCalculate(kerasOCRTypedPath)\n",
    "            kerasOCRWrittenText = openCalculate(kerasOCRWrittenPath)\n",
    "            easyOCRTypedText = openCalculate(easyOCRTypedPath)\n",
    "            easyOCRWrittenText = openCalculate(easyOCRWrittenPath)\n",
    "\n",
    "            # Calculate similarities\n",
    "            pyTesseractTypedScoreLev = calculate_similarity_lev(pyTesseractTypedText, groundTruthText)\n",
    "            pyTesseractWrittenScoreLev = calculate_similarity_lev(pyTesseractWrittenText, groundTruthText)\n",
    "            kerasOCRTypedScoreLev = calculate_similarity_lev(kerasOCRTypedText, groundTruthText)\n",
    "            kerasOCRWrittenScoreLev = calculate_similarity_lev(kerasOCRWrittenText, groundTruthText)\n",
    "            easyOCRTypedScoreLev = calculate_similarity_lev(easyOCRTypedText, groundTruthText)\n",
    "            easyOCRWrittenScoreLev = calculate_similarity_lev(easyOCRWrittenText, groundTruthText)\n",
    "            \n",
    "            print(f\"File: {filename}\")\n",
    "            print(f\"Similarity Percentage from Levenshtein with PyTesseract Typed: {pyTesseractTypedScoreLev:.2f}%\")\n",
    "            print(f\"Similarity Percentage from Levenshtein with PyTesseract Written: {pyTesseractWrittenScoreLev:.2f}%\")\n",
    "            print(f\"Similarity Percentage from Levenshtein with Keras OCR Typed: {kerasOCRTypedScoreLev:.2f}%\")\n",
    "            print(f\"Similarity Percentage from Levenshtein with Keras OCR Written: {kerasOCRWrittenScoreLev:.2f}%\")\n",
    "            print(f\"Similarity Percentage from Levenshtein with Easy OCR Typed: {easyOCRTypedScoreLev:.2f}%\")\n",
    "            print(f\"Similarity Percentage from Levenshtein with Easy OCR Written: {easyOCRWrittenScoreLev:.2f}%\")\n",
    "            \n",
    "            # Accumulate scores\n",
    "            count += 1\n",
    "            pyTesseractTypedScore += pyTesseractTypedScoreLev\n",
    "            pyTesseractWrittenScore += pyTesseractWrittenScoreLev\n",
    "            kerasOCRTypedScore += kerasOCRTypedScoreLev\n",
    "            kerasOCRWrittenScore += kerasOCRWrittenScoreLev\n",
    "            easyOCRTypedScore += easyOCRTypedScoreLev\n",
    "            easyOCRWrittenScore += easyOCRWrittenScoreLev            \n",
    "        else:\n",
    "            print(f\"Expected output not found for {filename}\")\n",
    "\n",
    "    # Calculate averages and return results\n",
    "    if count > 0:\n",
    "        result = {\n",
    "            \"pytesseract Typed\": pyTesseractTypedScore / count,\n",
    "            \"pytesseract Written\": pyTesseractWrittenScore / count,\n",
    "            \"kerasOCR Typed\": kerasOCRTypedScore / count,\n",
    "            \"kerasOCR Written\": kerasOCRWrittenScore / count,\n",
    "            \"easyOCR Typed\": easyOCRTypedScore / count,\n",
    "            \"easyOCR Written\": easyOCRWrittenScore / count\n",
    "        }\n",
    "        return result\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pytesseract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST_0001.jpg\n",
      "Text extracted from TEST_0001.jpg and saved to output-name/pytesseract/TEST_0001.txt\n",
      "TEST_0002.jpg\n",
      "Text extracted from TEST_0002.jpg and saved to output-name/pytesseract/TEST_0002.txt\n",
      "TEST_0003.jpg\n",
      "Text extracted from TEST_0003.jpg and saved to output-name/pytesseract/TEST_0003.txt\n",
      "TEST_0004.jpg\n",
      "Text extracted from TEST_0004.jpg and saved to output-name/pytesseract/TEST_0004.txt\n",
      "TEST_0005.jpg\n",
      "Text extracted from TEST_0005.jpg and saved to output-name/pytesseract/TEST_0005.txt\n",
      "TEST_0006.jpg\n",
      "Text extracted from TEST_0006.jpg and saved to output-name/pytesseract/TEST_0006.txt\n",
      "TEST_0007.jpg\n",
      "Text extracted from TEST_0007.jpg and saved to output-name/pytesseract/TEST_0007.txt\n",
      "TEST_0008.jpg\n",
      "Text extracted from TEST_0008.jpg and saved to output-name/pytesseract/TEST_0008.txt\n",
      "TEST_0009.jpg\n",
      "Text extracted from TEST_0009.jpg and saved to output-name/pytesseract/TEST_0009.txt\n",
      "TEST_0010.jpg\n",
      "Text extracted from TEST_0010.jpg and saved to output-name/pytesseract/TEST_0010.txt\n",
      "TEST_0011.jpg\n",
      "Text extracted from TEST_0011.jpg and saved to output-name/pytesseract/TEST_0011.txt\n",
      "TEST_0012.jpg\n",
      "Text extracted from TEST_0012.jpg and saved to output-name/pytesseract/TEST_0012.txt\n",
      "TEST_0013.jpg\n",
      "Text extracted from TEST_0013.jpg and saved to output-name/pytesseract/TEST_0013.txt\n",
      "TEST_0014.jpg\n",
      "Text extracted from TEST_0014.jpg and saved to output-name/pytesseract/TEST_0014.txt\n",
      "TEST_0015.jpg\n",
      "Text extracted from TEST_0015.jpg and saved to output-name/pytesseract/TEST_0015.txt\n",
      "TEST_0016.jpg\n",
      "Text extracted from TEST_0016.jpg and saved to output-name/pytesseract/TEST_0016.txt\n",
      "TEST_0017.jpg\n",
      "Text extracted from TEST_0017.jpg and saved to output-name/pytesseract/TEST_0017.txt\n",
      "TEST_0018.jpg\n",
      "Text extracted from TEST_0018.jpg and saved to output-name/pytesseract/TEST_0018.txt\n",
      "TEST_0019.jpg\n",
      "Text extracted from TEST_0019.jpg and saved to output-name/pytesseract/TEST_0019.txt\n",
      "TEST_0020.jpg\n",
      "Text extracted from TEST_0020.jpg and saved to output-name/pytesseract/TEST_0020.txt\n",
      "TEST_0021.jpg\n",
      "Text extracted from TEST_0021.jpg and saved to output-name/pytesseract/TEST_0021.txt\n",
      "TEST_0022.jpg\n",
      "Text extracted from TEST_0022.jpg and saved to output-name/pytesseract/TEST_0022.txt\n",
      "TEST_0023.jpg\n",
      "Text extracted from TEST_0023.jpg and saved to output-name/pytesseract/TEST_0023.txt\n",
      "TEST_0024.jpg\n",
      "Text extracted from TEST_0024.jpg and saved to output-name/pytesseract/TEST_0024.txt\n",
      "TEST_0025.jpg\n",
      "Text extracted from TEST_0025.jpg and saved to output-name/pytesseract/TEST_0025.txt\n",
      "TEST_0026.jpg\n",
      "Text extracted from TEST_0026.jpg and saved to output-name/pytesseract/TEST_0026.txt\n",
      "TEST_0027.jpg\n",
      "Text extracted from TEST_0027.jpg and saved to output-name/pytesseract/TEST_0027.txt\n",
      "TEST_0028.jpg\n",
      "Text extracted from TEST_0028.jpg and saved to output-name/pytesseract/TEST_0028.txt\n",
      "TEST_0029.jpg\n",
      "Text extracted from TEST_0029.jpg and saved to output-name/pytesseract/TEST_0029.txt\n",
      "TEST_0030.jpg\n",
      "Text extracted from TEST_0030.jpg and saved to output-name/pytesseract/TEST_0030.txt\n",
      "TEST_0031.jpg\n",
      "Text extracted from TEST_0031.jpg and saved to output-name/pytesseract/TEST_0031.txt\n",
      "TEST_0032.jpg\n",
      "Text extracted from TEST_0032.jpg and saved to output-name/pytesseract/TEST_0032.txt\n",
      "TEST_0033.jpg\n",
      "Text extracted from TEST_0033.jpg and saved to output-name/pytesseract/TEST_0033.txt\n",
      "TEST_0034.jpg\n",
      "Text extracted from TEST_0034.jpg and saved to output-name/pytesseract/TEST_0034.txt\n",
      "TEST_0035.jpg\n",
      "Text extracted from TEST_0035.jpg and saved to output-name/pytesseract/TEST_0035.txt\n",
      "TEST_0036.jpg\n",
      "Text extracted from TEST_0036.jpg and saved to output-name/pytesseract/TEST_0036.txt\n",
      "TEST_0037.jpg\n",
      "Text extracted from TEST_0037.jpg and saved to output-name/pytesseract/TEST_0037.txt\n",
      "TEST_0038.jpg\n",
      "Text extracted from TEST_0038.jpg and saved to output-name/pytesseract/TEST_0038.txt\n",
      "TEST_0039.jpg\n",
      "Text extracted from TEST_0039.jpg and saved to output-name/pytesseract/TEST_0039.txt\n",
      "TEST_0040.jpg\n",
      "Text extracted from TEST_0040.jpg and saved to output-name/pytesseract/TEST_0040.txt\n",
      "TEST_0041.jpg\n",
      "Text extracted from TEST_0041.jpg and saved to output-name/pytesseract/TEST_0041.txt\n",
      "TEST_0042.jpg\n",
      "Text extracted from TEST_0042.jpg and saved to output-name/pytesseract/TEST_0042.txt\n",
      "TEST_0043.jpg\n",
      "Text extracted from TEST_0043.jpg and saved to output-name/pytesseract/TEST_0043.txt\n",
      "TEST_0044.jpg\n",
      "Text extracted from TEST_0044.jpg and saved to output-name/pytesseract/TEST_0044.txt\n",
      "TEST_0045.jpg\n",
      "Text extracted from TEST_0045.jpg and saved to output-name/pytesseract/TEST_0045.txt\n",
      "TEST_0046.jpg\n",
      "Text extracted from TEST_0046.jpg and saved to output-name/pytesseract/TEST_0046.txt\n",
      "TEST_0047.jpg\n",
      "Text extracted from TEST_0047.jpg and saved to output-name/pytesseract/TEST_0047.txt\n",
      "TEST_0048.jpg\n",
      "Text extracted from TEST_0048.jpg and saved to output-name/pytesseract/TEST_0048.txt\n",
      "TEST_0049.jpg\n",
      "Text extracted from TEST_0049.jpg and saved to output-name/pytesseract/TEST_0049.txt\n",
      "TEST_0050.jpg\n",
      "Text extracted from TEST_0050.jpg and saved to output-name/pytesseract/TEST_0050.txt\n",
      "TEST_0051.jpg\n",
      "Text extracted from TEST_0051.jpg and saved to output-name/pytesseract/TEST_0051.txt\n",
      "TEST_0052.jpg\n",
      "Text extracted from TEST_0052.jpg and saved to output-name/pytesseract/TEST_0052.txt\n",
      "TEST_0053.jpg\n",
      "Text extracted from TEST_0053.jpg and saved to output-name/pytesseract/TEST_0053.txt\n",
      "TEST_0054.jpg\n",
      "Text extracted from TEST_0054.jpg and saved to output-name/pytesseract/TEST_0054.txt\n",
      "TEST_0055.jpg\n",
      "Text extracted from TEST_0055.jpg and saved to output-name/pytesseract/TEST_0055.txt\n",
      "TEST_0056.jpg\n",
      "Text extracted from TEST_0056.jpg and saved to output-name/pytesseract/TEST_0056.txt\n",
      "TEST_0057.jpg\n",
      "Text extracted from TEST_0057.jpg and saved to output-name/pytesseract/TEST_0057.txt\n",
      "TEST_0058.jpg\n",
      "Text extracted from TEST_0058.jpg and saved to output-name/pytesseract/TEST_0058.txt\n",
      "TEST_0059.jpg\n",
      "Text extracted from TEST_0059.jpg and saved to output-name/pytesseract/TEST_0059.txt\n",
      "TEST_0060.jpg\n",
      "Text extracted from TEST_0060.jpg and saved to output-name/pytesseract/TEST_0060.txt\n",
      "TEST_0061.jpg\n",
      "Text extracted from TEST_0061.jpg and saved to output-name/pytesseract/TEST_0061.txt\n",
      "TEST_0062.jpg\n",
      "Text extracted from TEST_0062.jpg and saved to output-name/pytesseract/TEST_0062.txt\n",
      "TEST_0063.jpg\n",
      "Text extracted from TEST_0063.jpg and saved to output-name/pytesseract/TEST_0063.txt\n",
      "TEST_0064.jpg\n",
      "Text extracted from TEST_0064.jpg and saved to output-name/pytesseract/TEST_0064.txt\n",
      "TEST_0065.jpg\n",
      "Text extracted from TEST_0065.jpg and saved to output-name/pytesseract/TEST_0065.txt\n",
      "TEST_0066.jpg\n",
      "Text extracted from TEST_0066.jpg and saved to output-name/pytesseract/TEST_0066.txt\n",
      "TEST_0067.jpg\n",
      "Text extracted from TEST_0067.jpg and saved to output-name/pytesseract/TEST_0067.txt\n",
      "TEST_0068.jpg\n",
      "Text extracted from TEST_0068.jpg and saved to output-name/pytesseract/TEST_0068.txt\n",
      "TEST_0069.jpg\n",
      "Text extracted from TEST_0069.jpg and saved to output-name/pytesseract/TEST_0069.txt\n",
      "TEST_0070.jpg\n",
      "Text extracted from TEST_0070.jpg and saved to output-name/pytesseract/TEST_0070.txt\n",
      "TEST_0071.jpg\n",
      "Text extracted from TEST_0071.jpg and saved to output-name/pytesseract/TEST_0071.txt\n",
      "TEST_0072.jpg\n",
      "Text extracted from TEST_0072.jpg and saved to output-name/pytesseract/TEST_0072.txt\n",
      "TEST_0073.jpg\n",
      "Text extracted from TEST_0073.jpg and saved to output-name/pytesseract/TEST_0073.txt\n",
      "TEST_0074.jpg\n",
      "Text extracted from TEST_0074.jpg and saved to output-name/pytesseract/TEST_0074.txt\n",
      "TEST_0075.jpg\n",
      "Text extracted from TEST_0075.jpg and saved to output-name/pytesseract/TEST_0075.txt\n",
      "TEST_0076.jpg\n",
      "Text extracted from TEST_0076.jpg and saved to output-name/pytesseract/TEST_0076.txt\n",
      "TEST_0077.jpg\n",
      "Text extracted from TEST_0077.jpg and saved to output-name/pytesseract/TEST_0077.txt\n",
      "TEST_0078.jpg\n",
      "Text extracted from TEST_0078.jpg and saved to output-name/pytesseract/TEST_0078.txt\n",
      "TEST_0079.jpg\n",
      "Text extracted from TEST_0079.jpg and saved to output-name/pytesseract/TEST_0079.txt\n",
      "TEST_0080.jpg\n",
      "Text extracted from TEST_0080.jpg and saved to output-name/pytesseract/TEST_0080.txt\n",
      "TEST_0081.jpg\n",
      "Text extracted from TEST_0081.jpg and saved to output-name/pytesseract/TEST_0081.txt\n",
      "TEST_0082.jpg\n",
      "Text extracted from TEST_0082.jpg and saved to output-name/pytesseract/TEST_0082.txt\n",
      "TEST_0083.jpg\n",
      "Text extracted from TEST_0083.jpg and saved to output-name/pytesseract/TEST_0083.txt\n",
      "TEST_0084.jpg\n",
      "Text extracted from TEST_0084.jpg and saved to output-name/pytesseract/TEST_0084.txt\n",
      "TEST_0085.jpg\n",
      "Text extracted from TEST_0085.jpg and saved to output-name/pytesseract/TEST_0085.txt\n",
      "TEST_0086.jpg\n",
      "Text extracted from TEST_0086.jpg and saved to output-name/pytesseract/TEST_0086.txt\n",
      "TEST_0087.jpg\n",
      "Text extracted from TEST_0087.jpg and saved to output-name/pytesseract/TEST_0087.txt\n",
      "TEST_0088.jpg\n",
      "Text extracted from TEST_0088.jpg and saved to output-name/pytesseract/TEST_0088.txt\n",
      "TEST_0089.jpg\n",
      "Text extracted from TEST_0089.jpg and saved to output-name/pytesseract/TEST_0089.txt\n",
      "TEST_0090.jpg\n",
      "Text extracted from TEST_0090.jpg and saved to output-name/pytesseract/TEST_0090.txt\n",
      "TEST_0091.jpg\n",
      "Text extracted from TEST_0091.jpg and saved to output-name/pytesseract/TEST_0091.txt\n",
      "TEST_0092.jpg\n",
      "Text extracted from TEST_0092.jpg and saved to output-name/pytesseract/TEST_0092.txt\n",
      "TEST_0093.jpg\n",
      "Text extracted from TEST_0093.jpg and saved to output-name/pytesseract/TEST_0093.txt\n",
      "TEST_0094.jpg\n",
      "Text extracted from TEST_0094.jpg and saved to output-name/pytesseract/TEST_0094.txt\n",
      "TEST_0095.jpg\n",
      "Text extracted from TEST_0095.jpg and saved to output-name/pytesseract/TEST_0095.txt\n",
      "TEST_0096.jpg\n",
      "Text extracted from TEST_0096.jpg and saved to output-name/pytesseract/TEST_0096.txt\n",
      "TEST_0097.jpg\n",
      "Text extracted from TEST_0097.jpg and saved to output-name/pytesseract/TEST_0097.txt\n",
      "TEST_0098.jpg\n",
      "Text extracted from TEST_0098.jpg and saved to output-name/pytesseract/TEST_0098.txt\n",
      "TEST_0099.jpg\n",
      "Text extracted from TEST_0099.jpg and saved to output-name/pytesseract/TEST_0099.txt\n",
      "TEST_0100.jpg\n",
      "Text extracted from TEST_0100.jpg and saved to output-name/pytesseract/TEST_0100.txt\n",
      "TEST_0101.jpg\n",
      "Text extracted from TEST_0101.jpg and saved to output-name/pytesseract/TEST_0101.txt\n",
      "TEST_0102.jpg\n",
      "Text extracted from TEST_0102.jpg and saved to output-name/pytesseract/TEST_0102.txt\n",
      "TEST_0103.jpg\n",
      "Text extracted from TEST_0103.jpg and saved to output-name/pytesseract/TEST_0103.txt\n",
      "TEST_0104.jpg\n",
      "Text extracted from TEST_0104.jpg and saved to output-name/pytesseract/TEST_0104.txt\n",
      "TEST_0105.jpg\n",
      "Text extracted from TEST_0105.jpg and saved to output-name/pytesseract/TEST_0105.txt\n",
      "TEST_0106.jpg\n",
      "Text extracted from TEST_0106.jpg and saved to output-name/pytesseract/TEST_0106.txt\n",
      "TEST_0107.jpg\n",
      "Text extracted from TEST_0107.jpg and saved to output-name/pytesseract/TEST_0107.txt\n",
      "TEST_0108.jpg\n",
      "Text extracted from TEST_0108.jpg and saved to output-name/pytesseract/TEST_0108.txt\n",
      "TEST_0109.jpg\n",
      "Text extracted from TEST_0109.jpg and saved to output-name/pytesseract/TEST_0109.txt\n",
      "TEST_0110.jpg\n",
      "Text extracted from TEST_0110.jpg and saved to output-name/pytesseract/TEST_0110.txt\n",
      "TEST_0111.jpg\n",
      "Text extracted from TEST_0111.jpg and saved to output-name/pytesseract/TEST_0111.txt\n",
      "TEST_0112.jpg\n",
      "Text extracted from TEST_0112.jpg and saved to output-name/pytesseract/TEST_0112.txt\n",
      "TEST_0113.jpg\n",
      "Text extracted from TEST_0113.jpg and saved to output-name/pytesseract/TEST_0113.txt\n",
      "TEST_0114.jpg\n",
      "Text extracted from TEST_0114.jpg and saved to output-name/pytesseract/TEST_0114.txt\n",
      "TEST_0115.jpg\n",
      "Text extracted from TEST_0115.jpg and saved to output-name/pytesseract/TEST_0115.txt\n",
      "TEST_0116.jpg\n",
      "Text extracted from TEST_0116.jpg and saved to output-name/pytesseract/TEST_0116.txt\n",
      "TEST_0117.jpg\n",
      "Text extracted from TEST_0117.jpg and saved to output-name/pytesseract/TEST_0117.txt\n",
      "TEST_0118.jpg\n",
      "Text extracted from TEST_0118.jpg and saved to output-name/pytesseract/TEST_0118.txt\n",
      "TEST_0119.jpg\n",
      "Text extracted from TEST_0119.jpg and saved to output-name/pytesseract/TEST_0119.txt\n",
      "TEST_0120.jpg\n",
      "Text extracted from TEST_0120.jpg and saved to output-name/pytesseract/TEST_0120.txt\n",
      "TEST_0121.jpg\n",
      "Text extracted from TEST_0121.jpg and saved to output-name/pytesseract/TEST_0121.txt\n",
      "TEST_0122.jpg\n",
      "Text extracted from TEST_0122.jpg and saved to output-name/pytesseract/TEST_0122.txt\n",
      "TEST_0123.jpg\n",
      "Text extracted from TEST_0123.jpg and saved to output-name/pytesseract/TEST_0123.txt\n",
      "TEST_0124.jpg\n",
      "Text extracted from TEST_0124.jpg and saved to output-name/pytesseract/TEST_0124.txt\n",
      "TEST_0125.jpg\n",
      "Text extracted from TEST_0125.jpg and saved to output-name/pytesseract/TEST_0125.txt\n",
      "TEST_0126.jpg\n",
      "Text extracted from TEST_0126.jpg and saved to output-name/pytesseract/TEST_0126.txt\n",
      "TEST_0127.jpg\n",
      "Text extracted from TEST_0127.jpg and saved to output-name/pytesseract/TEST_0127.txt\n",
      "TEST_0128.jpg\n",
      "Text extracted from TEST_0128.jpg and saved to output-name/pytesseract/TEST_0128.txt\n",
      "TEST_0129.jpg\n",
      "Text extracted from TEST_0129.jpg and saved to output-name/pytesseract/TEST_0129.txt\n",
      "TEST_0130.jpg\n",
      "Text extracted from TEST_0130.jpg and saved to output-name/pytesseract/TEST_0130.txt\n",
      "TEST_0131.jpg\n",
      "Text extracted from TEST_0131.jpg and saved to output-name/pytesseract/TEST_0131.txt\n",
      "TEST_0132.jpg\n",
      "Text extracted from TEST_0132.jpg and saved to output-name/pytesseract/TEST_0132.txt\n",
      "TEST_0133.jpg\n",
      "Text extracted from TEST_0133.jpg and saved to output-name/pytesseract/TEST_0133.txt\n",
      "TEST_0134.jpg\n",
      "Text extracted from TEST_0134.jpg and saved to output-name/pytesseract/TEST_0134.txt\n",
      "TEST_0135.jpg\n",
      "Text extracted from TEST_0135.jpg and saved to output-name/pytesseract/TEST_0135.txt\n",
      "TEST_0136.jpg\n",
      "Text extracted from TEST_0136.jpg and saved to output-name/pytesseract/TEST_0136.txt\n",
      "TEST_0137.jpg\n",
      "Text extracted from TEST_0137.jpg and saved to output-name/pytesseract/TEST_0137.txt\n",
      "TEST_0138.jpg\n",
      "Text extracted from TEST_0138.jpg and saved to output-name/pytesseract/TEST_0138.txt\n",
      "TEST_0139.jpg\n",
      "Text extracted from TEST_0139.jpg and saved to output-name/pytesseract/TEST_0139.txt\n",
      "TEST_0140.jpg\n",
      "Text extracted from TEST_0140.jpg and saved to output-name/pytesseract/TEST_0140.txt\n",
      "TEST_0141.jpg\n",
      "Text extracted from TEST_0141.jpg and saved to output-name/pytesseract/TEST_0141.txt\n",
      "TEST_0142.jpg\n",
      "Text extracted from TEST_0142.jpg and saved to output-name/pytesseract/TEST_0142.txt\n",
      "TEST_0143.jpg\n",
      "Text extracted from TEST_0143.jpg and saved to output-name/pytesseract/TEST_0143.txt\n",
      "TEST_0144.jpg\n",
      "Text extracted from TEST_0144.jpg and saved to output-name/pytesseract/TEST_0144.txt\n",
      "TEST_0145.jpg\n",
      "Text extracted from TEST_0145.jpg and saved to output-name/pytesseract/TEST_0145.txt\n",
      "TEST_0146.jpg\n",
      "Text extracted from TEST_0146.jpg and saved to output-name/pytesseract/TEST_0146.txt\n",
      "TEST_0147.jpg\n",
      "Text extracted from TEST_0147.jpg and saved to output-name/pytesseract/TEST_0147.txt\n",
      "TEST_0148.jpg\n",
      "Text extracted from TEST_0148.jpg and saved to output-name/pytesseract/TEST_0148.txt\n",
      "TEST_0149.jpg\n",
      "Text extracted from TEST_0149.jpg and saved to output-name/pytesseract/TEST_0149.txt\n",
      "TEST_0150.jpg\n",
      "Text extracted from TEST_0150.jpg and saved to output-name/pytesseract/TEST_0150.txt\n",
      "TEST_0151.jpg\n",
      "Text extracted from TEST_0151.jpg and saved to output-name/pytesseract/TEST_0151.txt\n",
      "TEST_0152.jpg\n",
      "Text extracted from TEST_0152.jpg and saved to output-name/pytesseract/TEST_0152.txt\n",
      "TEST_0153.jpg\n",
      "Text extracted from TEST_0153.jpg and saved to output-name/pytesseract/TEST_0153.txt\n",
      "TEST_0154.jpg\n",
      "Text extracted from TEST_0154.jpg and saved to output-name/pytesseract/TEST_0154.txt\n",
      "TEST_0155.jpg\n",
      "Text extracted from TEST_0155.jpg and saved to output-name/pytesseract/TEST_0155.txt\n",
      "TEST_0156.jpg\n",
      "Text extracted from TEST_0156.jpg and saved to output-name/pytesseract/TEST_0156.txt\n",
      "TEST_0157.jpg\n",
      "Text extracted from TEST_0157.jpg and saved to output-name/pytesseract/TEST_0157.txt\n",
      "TEST_0158.jpg\n",
      "Text extracted from TEST_0158.jpg and saved to output-name/pytesseract/TEST_0158.txt\n",
      "TEST_0159.jpg\n",
      "Text extracted from TEST_0159.jpg and saved to output-name/pytesseract/TEST_0159.txt\n",
      "TEST_0160.jpg\n",
      "Text extracted from TEST_0160.jpg and saved to output-name/pytesseract/TEST_0160.txt\n",
      "TEST_0161.jpg\n",
      "Text extracted from TEST_0161.jpg and saved to output-name/pytesseract/TEST_0161.txt\n",
      "TEST_0162.jpg\n",
      "Text extracted from TEST_0162.jpg and saved to output-name/pytesseract/TEST_0162.txt\n",
      "TEST_0163.jpg\n",
      "Text extracted from TEST_0163.jpg and saved to output-name/pytesseract/TEST_0163.txt\n",
      "TEST_0164.jpg\n",
      "Text extracted from TEST_0164.jpg and saved to output-name/pytesseract/TEST_0164.txt\n",
      "TEST_0165.jpg\n",
      "Text extracted from TEST_0165.jpg and saved to output-name/pytesseract/TEST_0165.txt\n",
      "TEST_0166.jpg\n",
      "Text extracted from TEST_0166.jpg and saved to output-name/pytesseract/TEST_0166.txt\n",
      "TEST_0167.jpg\n",
      "Text extracted from TEST_0167.jpg and saved to output-name/pytesseract/TEST_0167.txt\n",
      "TEST_0168.jpg\n",
      "Text extracted from TEST_0168.jpg and saved to output-name/pytesseract/TEST_0168.txt\n",
      "TEST_0169.jpg\n",
      "Text extracted from TEST_0169.jpg and saved to output-name/pytesseract/TEST_0169.txt\n",
      "TEST_0170.jpg\n",
      "Text extracted from TEST_0170.jpg and saved to output-name/pytesseract/TEST_0170.txt\n",
      "TEST_0171.jpg\n",
      "Text extracted from TEST_0171.jpg and saved to output-name/pytesseract/TEST_0171.txt\n",
      "TEST_0172.jpg\n",
      "Text extracted from TEST_0172.jpg and saved to output-name/pytesseract/TEST_0172.txt\n",
      "TEST_0173.jpg\n",
      "Text extracted from TEST_0173.jpg and saved to output-name/pytesseract/TEST_0173.txt\n",
      "TEST_0174.jpg\n",
      "Text extracted from TEST_0174.jpg and saved to output-name/pytesseract/TEST_0174.txt\n",
      "TEST_0175.jpg\n",
      "Text extracted from TEST_0175.jpg and saved to output-name/pytesseract/TEST_0175.txt\n",
      "TEST_0176.jpg\n",
      "Text extracted from TEST_0176.jpg and saved to output-name/pytesseract/TEST_0176.txt\n",
      "TEST_0177.jpg\n",
      "Text extracted from TEST_0177.jpg and saved to output-name/pytesseract/TEST_0177.txt\n",
      "TEST_0178.jpg\n",
      "Text extracted from TEST_0178.jpg and saved to output-name/pytesseract/TEST_0178.txt\n",
      "TEST_0179.jpg\n",
      "Text extracted from TEST_0179.jpg and saved to output-name/pytesseract/TEST_0179.txt\n",
      "TEST_0180.jpg\n",
      "Text extracted from TEST_0180.jpg and saved to output-name/pytesseract/TEST_0180.txt\n",
      "TEST_0181.jpg\n",
      "Text extracted from TEST_0181.jpg and saved to output-name/pytesseract/TEST_0181.txt\n",
      "TEST_0182.jpg\n",
      "Text extracted from TEST_0182.jpg and saved to output-name/pytesseract/TEST_0182.txt\n",
      "TEST_0183.jpg\n",
      "Text extracted from TEST_0183.jpg and saved to output-name/pytesseract/TEST_0183.txt\n",
      "TEST_0184.jpg\n",
      "Text extracted from TEST_0184.jpg and saved to output-name/pytesseract/TEST_0184.txt\n",
      "TEST_0185.jpg\n",
      "Text extracted from TEST_0185.jpg and saved to output-name/pytesseract/TEST_0185.txt\n",
      "TEST_0186.jpg\n",
      "Text extracted from TEST_0186.jpg and saved to output-name/pytesseract/TEST_0186.txt\n",
      "TEST_0187.jpg\n",
      "Text extracted from TEST_0187.jpg and saved to output-name/pytesseract/TEST_0187.txt\n",
      "TEST_0188.jpg\n",
      "Text extracted from TEST_0188.jpg and saved to output-name/pytesseract/TEST_0188.txt\n",
      "TEST_0189.jpg\n",
      "Text extracted from TEST_0189.jpg and saved to output-name/pytesseract/TEST_0189.txt\n",
      "TEST_0190.jpg\n",
      "Text extracted from TEST_0190.jpg and saved to output-name/pytesseract/TEST_0190.txt\n",
      "TEST_0191.jpg\n",
      "Text extracted from TEST_0191.jpg and saved to output-name/pytesseract/TEST_0191.txt\n",
      "TEST_0192.jpg\n",
      "Text extracted from TEST_0192.jpg and saved to output-name/pytesseract/TEST_0192.txt\n",
      "TEST_0193.jpg\n",
      "Text extracted from TEST_0193.jpg and saved to output-name/pytesseract/TEST_0193.txt\n",
      "TEST_0194.jpg\n",
      "Text extracted from TEST_0194.jpg and saved to output-name/pytesseract/TEST_0194.txt\n",
      "TEST_0195.jpg\n",
      "Text extracted from TEST_0195.jpg and saved to output-name/pytesseract/TEST_0195.txt\n",
      "TEST_0196.jpg\n",
      "Text extracted from TEST_0196.jpg and saved to output-name/pytesseract/TEST_0196.txt\n",
      "TEST_0197.jpg\n",
      "Text extracted from TEST_0197.jpg and saved to output-name/pytesseract/TEST_0197.txt\n",
      "TEST_0198.jpg\n",
      "Text extracted from TEST_0198.jpg and saved to output-name/pytesseract/TEST_0198.txt\n",
      "TEST_0199.jpg\n",
      "Text extracted from TEST_0199.jpg and saved to output-name/pytesseract/TEST_0199.txt\n",
      "TEST_0200.jpg\n",
      "Text extracted from TEST_0200.jpg and saved to output-name/pytesseract/TEST_0200.txt\n",
      "TEST_0201.jpg\n"
     ]
    }
   ],
   "source": [
    "import pytesseract\n",
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "#Tesseract executable\n",
    "pytesseract.pytesseract.tesseract_cmd = \"C:/Program Files/Tesseract-OCR/tesseract.exe\"\n",
    "\n",
    "imageWritten = 'cleaned/000-written'\n",
    "imageTyped = 'cleaned/000-typed'\n",
    "imageNameWritten = '1/test_v2/test'\n",
    "\n",
    "def processImagesPyTesseract(imageDirectory, outputDirectory, process):\n",
    "    pyTesseractTimes = {}\n",
    "    counter = 0\n",
    "    for filename in os.listdir(imageDirectory):\n",
    "        print(filename)\n",
    "        if counter == 200:\n",
    "            break\n",
    "        if filename.endswith('.png') or filename.endswith('jpg'):\n",
    "            image_path = os.path.join(imageDirectory, filename)\n",
    "\n",
    "            # Open using PIL (Need to open with RGB and not BGR)\n",
    "            img = Image.open(image_path)\n",
    "            if process:\n",
    "                img = cleanImage(img, \"tesseract\") \n",
    "\n",
    "            # Output file format\n",
    "            output_file =outputDirectory + os.path.splitext(filename)[0] + '.txt'\n",
    "\n",
    "            # Run Tesseract and writes into output file\n",
    "            with open(output_file, 'w') as f:\n",
    "                startTime = time.time()\n",
    "                text = pytesseract.image_to_string(img, config=\"--oem 3 --psm 6\") #better for written notes (oem 3 is best OCR engine [LSTM + Legacy], psm 6 assumes block text) \n",
    "                endTime = time.time()\n",
    "                pyTesseractTimes[filename] = endTime - startTime\n",
    "                f.write(text)\n",
    "\n",
    "            print(f\"Text extracted from {filename} and saved to {output_file}\")\n",
    "        counter += 1\n",
    "    return pyTesseractTimes\n",
    "#Uncomment to run PyTesseract on images\n",
    "#print(\"Processing images in directory (PyTesseract):\", imageWritten)\n",
    "#pyTesseractWrittenTime= processImagesPyTesseract(imageWritten, \"pyWritten\", False)\n",
    "#print(\"\\nProcessing images in directory  (PyTesseract):\", imageTyped)\n",
    "#pyTesseractTypedTime=processImagesPyTesseract(imageTyped, \"pyTyped\", False)\n",
    "temp = processImagesPyTesseract(imageNameWritten, \"output-name/pytesseract/\", False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keras OCR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking for C:\\Users\\adam4\\.keras-ocr\\craft_mlt_25k.h5\n",
      "Looking for C:\\Users\\adam4\\.keras-ocr\\crnn_kurapan.h5\n",
      "Testing image:  TEST_0001.jpg\n",
      "Testing image:  TEST_0002.jpg\n",
      "Testing image:  TEST_0003.jpg\n",
      "Testing image:  TEST_0004.jpg\n",
      "Testing image:  TEST_0005.jpg\n",
      "Testing image:  TEST_0006.jpg\n",
      "Testing image:  TEST_0007.jpg\n",
      "Testing image:  TEST_0008.jpg\n",
      "Testing image:  TEST_0009.jpg\n",
      "Testing image:  TEST_0010.jpg\n",
      "Testing image:  TEST_0011.jpg\n",
      "Testing image:  TEST_0012.jpg\n",
      "Testing image:  TEST_0013.jpg\n",
      "Testing image:  TEST_0014.jpg\n",
      "Testing image:  TEST_0015.jpg\n",
      "Testing image:  TEST_0016.jpg\n",
      "Testing image:  TEST_0017.jpg\n",
      "Testing image:  TEST_0018.jpg\n",
      "Testing image:  TEST_0019.jpg\n",
      "Testing image:  TEST_0020.jpg\n",
      "Testing image:  TEST_0021.jpg\n",
      "Testing image:  TEST_0022.jpg\n",
      "Testing image:  TEST_0023.jpg\n",
      "Testing image:  TEST_0024.jpg\n",
      "Testing image:  TEST_0025.jpg\n",
      "Testing image:  TEST_0026.jpg\n",
      "Testing image:  TEST_0027.jpg\n",
      "Testing image:  TEST_0028.jpg\n",
      "Testing image:  TEST_0029.jpg\n",
      "Testing image:  TEST_0030.jpg\n",
      "Testing image:  TEST_0031.jpg\n",
      "Testing image:  TEST_0032.jpg\n",
      "Testing image:  TEST_0033.jpg\n",
      "Testing image:  TEST_0034.jpg\n",
      "Testing image:  TEST_0035.jpg\n",
      "Testing image:  TEST_0036.jpg\n",
      "Testing image:  TEST_0037.jpg\n",
      "Testing image:  TEST_0038.jpg\n",
      "Testing image:  TEST_0039.jpg\n",
      "Testing image:  TEST_0040.jpg\n",
      "Testing image:  TEST_0041.jpg\n",
      "Testing image:  TEST_0042.jpg\n",
      "Testing image:  TEST_0043.jpg\n",
      "Testing image:  TEST_0044.jpg\n",
      "Testing image:  TEST_0045.jpg\n",
      "Testing image:  TEST_0046.jpg\n",
      "Testing image:  TEST_0047.jpg\n",
      "Testing image:  TEST_0048.jpg\n",
      "Testing image:  TEST_0049.jpg\n",
      "Testing image:  TEST_0050.jpg\n",
      "Testing image:  TEST_0051.jpg\n",
      "Testing image:  TEST_0052.jpg\n",
      "Testing image:  TEST_0053.jpg\n",
      "Testing image:  TEST_0054.jpg\n",
      "Testing image:  TEST_0055.jpg\n",
      "Testing image:  TEST_0056.jpg\n",
      "Testing image:  TEST_0057.jpg\n",
      "Testing image:  TEST_0058.jpg\n",
      "Testing image:  TEST_0059.jpg\n",
      "Testing image:  TEST_0060.jpg\n",
      "Testing image:  TEST_0061.jpg\n",
      "Testing image:  TEST_0062.jpg\n",
      "Testing image:  TEST_0063.jpg\n",
      "Testing image:  TEST_0064.jpg\n",
      "Testing image:  TEST_0065.jpg\n",
      "Testing image:  TEST_0066.jpg\n",
      "Testing image:  TEST_0067.jpg\n",
      "Testing image:  TEST_0068.jpg\n",
      "Testing image:  TEST_0069.jpg\n",
      "Testing image:  TEST_0070.jpg\n",
      "Testing image:  TEST_0071.jpg\n",
      "Testing image:  TEST_0072.jpg\n",
      "Testing image:  TEST_0073.jpg\n",
      "Testing image:  TEST_0074.jpg\n",
      "Testing image:  TEST_0075.jpg\n",
      "Testing image:  TEST_0076.jpg\n",
      "Testing image:  TEST_0077.jpg\n",
      "Testing image:  TEST_0078.jpg\n",
      "Testing image:  TEST_0079.jpg\n",
      "Testing image:  TEST_0080.jpg\n",
      "Testing image:  TEST_0081.jpg\n",
      "Testing image:  TEST_0082.jpg\n",
      "Testing image:  TEST_0083.jpg\n",
      "Testing image:  TEST_0084.jpg\n",
      "Testing image:  TEST_0085.jpg\n",
      "Testing image:  TEST_0086.jpg\n",
      "Testing image:  TEST_0087.jpg\n",
      "Testing image:  TEST_0088.jpg\n",
      "Testing image:  TEST_0089.jpg\n",
      "Testing image:  TEST_0090.jpg\n",
      "Testing image:  TEST_0091.jpg\n",
      "Testing image:  TEST_0092.jpg\n",
      "Testing image:  TEST_0093.jpg\n",
      "Testing image:  TEST_0094.jpg\n",
      "Testing image:  TEST_0095.jpg\n",
      "Testing image:  TEST_0096.jpg\n",
      "Testing image:  TEST_0097.jpg\n",
      "Testing image:  TEST_0098.jpg\n",
      "Testing image:  TEST_0099.jpg\n",
      "Testing image:  TEST_0100.jpg\n",
      "Testing image:  TEST_0101.jpg\n",
      "Testing image:  TEST_0102.jpg\n",
      "Testing image:  TEST_0103.jpg\n",
      "Testing image:  TEST_0104.jpg\n",
      "Testing image:  TEST_0105.jpg\n",
      "Testing image:  TEST_0106.jpg\n",
      "Testing image:  TEST_0107.jpg\n",
      "Testing image:  TEST_0108.jpg\n",
      "Testing image:  TEST_0109.jpg\n",
      "Testing image:  TEST_0110.jpg\n",
      "Testing image:  TEST_0111.jpg\n",
      "Testing image:  TEST_0112.jpg\n",
      "Testing image:  TEST_0113.jpg\n",
      "Testing image:  TEST_0114.jpg\n",
      "Testing image:  TEST_0115.jpg\n",
      "Testing image:  TEST_0116.jpg\n",
      "Testing image:  TEST_0117.jpg\n",
      "Testing image:  TEST_0118.jpg\n",
      "Testing image:  TEST_0119.jpg\n",
      "Testing image:  TEST_0120.jpg\n",
      "Testing image:  TEST_0121.jpg\n",
      "Testing image:  TEST_0122.jpg\n",
      "Testing image:  TEST_0123.jpg\n",
      "Testing image:  TEST_0124.jpg\n",
      "Testing image:  TEST_0125.jpg\n",
      "Testing image:  TEST_0126.jpg\n",
      "Testing image:  TEST_0127.jpg\n",
      "Testing image:  TEST_0128.jpg\n",
      "Testing image:  TEST_0129.jpg\n",
      "Testing image:  TEST_0130.jpg\n",
      "Testing image:  TEST_0131.jpg\n",
      "Testing image:  TEST_0132.jpg\n",
      "Testing image:  TEST_0133.jpg\n",
      "Testing image:  TEST_0134.jpg\n",
      "Testing image:  TEST_0135.jpg\n",
      "Testing image:  TEST_0136.jpg\n",
      "Testing image:  TEST_0137.jpg\n",
      "Testing image:  TEST_0138.jpg\n",
      "Testing image:  TEST_0139.jpg\n",
      "Testing image:  TEST_0140.jpg\n",
      "Testing image:  TEST_0141.jpg\n",
      "Testing image:  TEST_0142.jpg\n",
      "Testing image:  TEST_0143.jpg\n",
      "Testing image:  TEST_0144.jpg\n",
      "Testing image:  TEST_0145.jpg\n",
      "Testing image:  TEST_0146.jpg\n",
      "Testing image:  TEST_0147.jpg\n",
      "Testing image:  TEST_0148.jpg\n",
      "Testing image:  TEST_0149.jpg\n",
      "Testing image:  TEST_0150.jpg\n",
      "Testing image:  TEST_0151.jpg\n",
      "Testing image:  TEST_0152.jpg\n",
      "Testing image:  TEST_0153.jpg\n",
      "Testing image:  TEST_0154.jpg\n",
      "Testing image:  TEST_0155.jpg\n",
      "Testing image:  TEST_0156.jpg\n",
      "Testing image:  TEST_0157.jpg\n",
      "Testing image:  TEST_0158.jpg\n",
      "Testing image:  TEST_0159.jpg\n",
      "Testing image:  TEST_0160.jpg\n",
      "Testing image:  TEST_0161.jpg\n",
      "Testing image:  TEST_0162.jpg\n",
      "Testing image:  TEST_0163.jpg\n",
      "Testing image:  TEST_0164.jpg\n",
      "Testing image:  TEST_0165.jpg\n",
      "Testing image:  TEST_0166.jpg\n",
      "Testing image:  TEST_0167.jpg\n",
      "Testing image:  TEST_0168.jpg\n",
      "Testing image:  TEST_0169.jpg\n",
      "Testing image:  TEST_0170.jpg\n",
      "Testing image:  TEST_0171.jpg\n",
      "Testing image:  TEST_0172.jpg\n",
      "Testing image:  TEST_0173.jpg\n",
      "Testing image:  TEST_0174.jpg\n",
      "Testing image:  TEST_0175.jpg\n",
      "Testing image:  TEST_0176.jpg\n",
      "Testing image:  TEST_0177.jpg\n",
      "Testing image:  TEST_0178.jpg\n",
      "Testing image:  TEST_0179.jpg\n",
      "Testing image:  TEST_0180.jpg\n",
      "Testing image:  TEST_0181.jpg\n",
      "Testing image:  TEST_0182.jpg\n",
      "Testing image:  TEST_0183.jpg\n",
      "Testing image:  TEST_0184.jpg\n",
      "Testing image:  TEST_0185.jpg\n",
      "Testing image:  TEST_0186.jpg\n",
      "Testing image:  TEST_0187.jpg\n",
      "Testing image:  TEST_0188.jpg\n",
      "Testing image:  TEST_0189.jpg\n",
      "Testing image:  TEST_0190.jpg\n",
      "Testing image:  TEST_0191.jpg\n",
      "Testing image:  TEST_0192.jpg\n",
      "Testing image:  TEST_0193.jpg\n",
      "Testing image:  TEST_0194.jpg\n",
      "Testing image:  TEST_0195.jpg\n",
      "Testing image:  TEST_0196.jpg\n",
      "Testing image:  TEST_0197.jpg\n",
      "Testing image:  TEST_0198.jpg\n",
      "Testing image:  TEST_0199.jpg\n",
      "Testing image:  TEST_0200.jpg\n",
      "7/7 [==============================] - 43s 6s/step\n",
      "20/20 [==============================] - 21s 937ms/step\n",
      "Writting into:  1/test_v2/test\\TEST_0001.txt\n",
      "Writting into:  1/test_v2/test\\TEST_0002.txt\n",
      "Writting into:  1/test_v2/test\\TEST_0003.txt\n",
      "Writting into:  1/test_v2/test\\TEST_0004.txt\n",
      "Writting into:  1/test_v2/test\\TEST_0005.txt\n",
      "Writting into:  1/test_v2/test\\TEST_0006.txt\n",
      "Writting into:  1/test_v2/test\\TEST_0007.txt\n",
      "Writting into:  1/test_v2/test\\TEST_0008.txt\n",
      "Writting into:  1/test_v2/test\\TEST_0009.txt\n",
      "Writting into:  1/test_v2/test\\TEST_0010.txt\n",
      "Writting into:  1/test_v2/test\\TEST_0011.txt\n",
      "Writting into:  1/test_v2/test\\TEST_0012.txt\n",
      "Writting into:  1/test_v2/test\\TEST_0013.txt\n",
      "Writting into:  1/test_v2/test\\TEST_0014.txt\n",
      "Writting into:  1/test_v2/test\\TEST_0015.txt\n",
      "Writting into:  1/test_v2/test\\TEST_0016.txt\n",
      "Writting into:  1/test_v2/test\\TEST_0017.txt\n",
      "Writting into:  1/test_v2/test\\TEST_0018.txt\n",
      "Writting into:  1/test_v2/test\\TEST_0019.txt\n",
      "Writting into:  1/test_v2/test\\TEST_0020.txt\n",
      "Writting into:  1/test_v2/test\\TEST_0021.txt\n",
      "Writting into:  1/test_v2/test\\TEST_0022.txt\n",
      "Writting into:  1/test_v2/test\\TEST_0023.txt\n",
      "Writting into:  1/test_v2/test\\TEST_0024.txt\n",
      "Writting into:  1/test_v2/test\\TEST_0025.txt\n",
      "Writting into:  1/test_v2/test\\TEST_0026.txt\n",
      "Writting into:  1/test_v2/test\\TEST_0027.txt\n",
      "Writting into:  1/test_v2/test\\TEST_0028.txt\n",
      "Writting into:  1/test_v2/test\\TEST_0029.txt\n",
      "Writting into:  1/test_v2/test\\TEST_0030.txt\n",
      "Writting into:  1/test_v2/test\\TEST_0031.txt\n",
      "Writting into:  1/test_v2/test\\TEST_0032.txt\n",
      "Writting into:  1/test_v2/test\\TEST_0033.txt\n",
      "Writting into:  1/test_v2/test\\TEST_0034.txt\n",
      "Writting into:  1/test_v2/test\\TEST_0035.txt\n",
      "Writting into:  1/test_v2/test\\TEST_0036.txt\n",
      "Writting into:  1/test_v2/test\\TEST_0037.txt\n",
      "Writting into:  1/test_v2/test\\TEST_0038.txt\n",
      "Writting into:  1/test_v2/test\\TEST_0039.txt\n",
      "Writting into:  1/test_v2/test\\TEST_0040.txt\n",
      "Writting into:  1/test_v2/test\\TEST_0041.txt\n",
      "Writting into:  1/test_v2/test\\TEST_0042.txt\n",
      "Writting into:  1/test_v2/test\\TEST_0043.txt\n",
      "Writting into:  1/test_v2/test\\TEST_0044.txt\n",
      "Writting into:  1/test_v2/test\\TEST_0045.txt\n",
      "Writting into:  1/test_v2/test\\TEST_0046.txt\n",
      "Writting into:  1/test_v2/test\\TEST_0047.txt\n",
      "Writting into:  1/test_v2/test\\TEST_0048.txt\n",
      "Writting into:  1/test_v2/test\\TEST_0049.txt\n",
      "Writting into:  1/test_v2/test\\TEST_0050.txt\n",
      "Writting into:  1/test_v2/test\\TEST_0051.txt\n",
      "Writting into:  1/test_v2/test\\TEST_0052.txt\n",
      "Writting into:  1/test_v2/test\\TEST_0053.txt\n",
      "Writting into:  1/test_v2/test\\TEST_0054.txt\n",
      "Writting into:  1/test_v2/test\\TEST_0055.txt\n",
      "Writting into:  1/test_v2/test\\TEST_0056.txt\n",
      "Writting into:  1/test_v2/test\\TEST_0057.txt\n",
      "Writting into:  1/test_v2/test\\TEST_0058.txt\n",
      "Writting into:  1/test_v2/test\\TEST_0059.txt\n",
      "Writting into:  1/test_v2/test\\TEST_0060.txt\n",
      "Writting into:  1/test_v2/test\\TEST_0061.txt\n",
      "Writting into:  1/test_v2/test\\TEST_0062.txt\n",
      "Writting into:  1/test_v2/test\\TEST_0063.txt\n",
      "Writting into:  1/test_v2/test\\TEST_0064.txt\n",
      "Writting into:  1/test_v2/test\\TEST_0065.txt\n",
      "Writting into:  1/test_v2/test\\TEST_0066.txt\n",
      "Writting into:  1/test_v2/test\\TEST_0067.txt\n",
      "Writting into:  1/test_v2/test\\TEST_0068.txt\n",
      "Writting into:  1/test_v2/test\\TEST_0069.txt\n",
      "Writting into:  1/test_v2/test\\TEST_0070.txt\n",
      "Writting into:  1/test_v2/test\\TEST_0071.txt\n",
      "Writting into:  1/test_v2/test\\TEST_0072.txt\n",
      "Writting into:  1/test_v2/test\\TEST_0073.txt\n",
      "Writting into:  1/test_v2/test\\TEST_0074.txt\n",
      "Writting into:  1/test_v2/test\\TEST_0075.txt\n",
      "Writting into:  1/test_v2/test\\TEST_0076.txt\n",
      "Writting into:  1/test_v2/test\\TEST_0077.txt\n",
      "Writting into:  1/test_v2/test\\TEST_0078.txt\n",
      "Writting into:  1/test_v2/test\\TEST_0079.txt\n",
      "Writting into:  1/test_v2/test\\TEST_0080.txt\n",
      "Writting into:  1/test_v2/test\\TEST_0081.txt\n",
      "Writting into:  1/test_v2/test\\TEST_0082.txt\n",
      "Writting into:  1/test_v2/test\\TEST_0083.txt\n",
      "Writting into:  1/test_v2/test\\TEST_0084.txt\n",
      "Writting into:  1/test_v2/test\\TEST_0085.txt\n",
      "Writting into:  1/test_v2/test\\TEST_0086.txt\n",
      "Writting into:  1/test_v2/test\\TEST_0087.txt\n",
      "Writting into:  1/test_v2/test\\TEST_0088.txt\n",
      "Writting into:  1/test_v2/test\\TEST_0089.txt\n",
      "Writting into:  1/test_v2/test\\TEST_0090.txt\n",
      "Writting into:  1/test_v2/test\\TEST_0091.txt\n",
      "Writting into:  1/test_v2/test\\TEST_0092.txt\n",
      "Writting into:  1/test_v2/test\\TEST_0093.txt\n",
      "Writting into:  1/test_v2/test\\TEST_0094.txt\n",
      "Writting into:  1/test_v2/test\\TEST_0095.txt\n",
      "Writting into:  1/test_v2/test\\TEST_0096.txt\n",
      "Writting into:  1/test_v2/test\\TEST_0097.txt\n",
      "Writting into:  1/test_v2/test\\TEST_0098.txt\n",
      "Writting into:  1/test_v2/test\\TEST_0099.txt\n",
      "Writting into:  1/test_v2/test\\TEST_0100.txt\n",
      "Writting into:  1/test_v2/test\\TEST_0101.txt\n",
      "Writting into:  1/test_v2/test\\TEST_0102.txt\n",
      "Writting into:  1/test_v2/test\\TEST_0103.txt\n",
      "Writting into:  1/test_v2/test\\TEST_0104.txt\n",
      "Writting into:  1/test_v2/test\\TEST_0105.txt\n",
      "Writting into:  1/test_v2/test\\TEST_0106.txt\n",
      "Writting into:  1/test_v2/test\\TEST_0107.txt\n",
      "Writting into:  1/test_v2/test\\TEST_0108.txt\n",
      "Writting into:  1/test_v2/test\\TEST_0109.txt\n",
      "Writting into:  1/test_v2/test\\TEST_0110.txt\n",
      "Writting into:  1/test_v2/test\\TEST_0111.txt\n",
      "Writting into:  1/test_v2/test\\TEST_0112.txt\n",
      "Writting into:  1/test_v2/test\\TEST_0113.txt\n",
      "Writting into:  1/test_v2/test\\TEST_0114.txt\n",
      "Writting into:  1/test_v2/test\\TEST_0115.txt\n",
      "Writting into:  1/test_v2/test\\TEST_0116.txt\n",
      "Writting into:  1/test_v2/test\\TEST_0117.txt\n",
      "Writting into:  1/test_v2/test\\TEST_0118.txt\n",
      "Writting into:  1/test_v2/test\\TEST_0119.txt\n",
      "Writting into:  1/test_v2/test\\TEST_0120.txt\n",
      "Writting into:  1/test_v2/test\\TEST_0121.txt\n",
      "Writting into:  1/test_v2/test\\TEST_0122.txt\n",
      "Writting into:  1/test_v2/test\\TEST_0123.txt\n",
      "Writting into:  1/test_v2/test\\TEST_0124.txt\n",
      "Writting into:  1/test_v2/test\\TEST_0125.txt\n",
      "Writting into:  1/test_v2/test\\TEST_0126.txt\n",
      "Writting into:  1/test_v2/test\\TEST_0127.txt\n",
      "Writting into:  1/test_v2/test\\TEST_0128.txt\n",
      "Writting into:  1/test_v2/test\\TEST_0129.txt\n",
      "Writting into:  1/test_v2/test\\TEST_0130.txt\n",
      "Writting into:  1/test_v2/test\\TEST_0131.txt\n",
      "Writting into:  1/test_v2/test\\TEST_0132.txt\n",
      "Writting into:  1/test_v2/test\\TEST_0133.txt\n",
      "Writting into:  1/test_v2/test\\TEST_0134.txt\n",
      "Writting into:  1/test_v2/test\\TEST_0135.txt\n",
      "Writting into:  1/test_v2/test\\TEST_0136.txt\n",
      "Writting into:  1/test_v2/test\\TEST_0137.txt\n",
      "Writting into:  1/test_v2/test\\TEST_0138.txt\n",
      "Writting into:  1/test_v2/test\\TEST_0139.txt\n",
      "Writting into:  1/test_v2/test\\TEST_0140.txt\n",
      "Writting into:  1/test_v2/test\\TEST_0141.txt\n",
      "Writting into:  1/test_v2/test\\TEST_0142.txt\n",
      "Writting into:  1/test_v2/test\\TEST_0143.txt\n",
      "Writting into:  1/test_v2/test\\TEST_0144.txt\n",
      "Writting into:  1/test_v2/test\\TEST_0145.txt\n",
      "Writting into:  1/test_v2/test\\TEST_0146.txt\n",
      "Writting into:  1/test_v2/test\\TEST_0147.txt\n",
      "Writting into:  1/test_v2/test\\TEST_0148.txt\n",
      "Writting into:  1/test_v2/test\\TEST_0149.txt\n",
      "Writting into:  1/test_v2/test\\TEST_0150.txt\n",
      "Writting into:  1/test_v2/test\\TEST_0151.txt\n",
      "Writting into:  1/test_v2/test\\TEST_0152.txt\n",
      "Writting into:  1/test_v2/test\\TEST_0153.txt\n",
      "Writting into:  1/test_v2/test\\TEST_0154.txt\n",
      "Writting into:  1/test_v2/test\\TEST_0155.txt\n",
      "Writting into:  1/test_v2/test\\TEST_0156.txt\n",
      "Writting into:  1/test_v2/test\\TEST_0157.txt\n",
      "Writting into:  1/test_v2/test\\TEST_0158.txt\n",
      "Writting into:  1/test_v2/test\\TEST_0159.txt\n",
      "Writting into:  1/test_v2/test\\TEST_0160.txt\n",
      "Writting into:  1/test_v2/test\\TEST_0161.txt\n",
      "Writting into:  1/test_v2/test\\TEST_0162.txt\n",
      "Writting into:  1/test_v2/test\\TEST_0163.txt\n",
      "Writting into:  1/test_v2/test\\TEST_0164.txt\n",
      "Writting into:  1/test_v2/test\\TEST_0165.txt\n",
      "Writting into:  1/test_v2/test\\TEST_0166.txt\n",
      "Writting into:  1/test_v2/test\\TEST_0167.txt\n",
      "Writting into:  1/test_v2/test\\TEST_0168.txt\n",
      "Writting into:  1/test_v2/test\\TEST_0169.txt\n",
      "Writting into:  1/test_v2/test\\TEST_0170.txt\n",
      "Writting into:  1/test_v2/test\\TEST_0171.txt\n",
      "Writting into:  1/test_v2/test\\TEST_0172.txt\n",
      "Writting into:  1/test_v2/test\\TEST_0173.txt\n",
      "Writting into:  1/test_v2/test\\TEST_0174.txt\n",
      "Writting into:  1/test_v2/test\\TEST_0175.txt\n",
      "Writting into:  1/test_v2/test\\TEST_0176.txt\n",
      "Writting into:  1/test_v2/test\\TEST_0177.txt\n",
      "Writting into:  1/test_v2/test\\TEST_0178.txt\n",
      "Writting into:  1/test_v2/test\\TEST_0179.txt\n",
      "Writting into:  1/test_v2/test\\TEST_0180.txt\n",
      "Writting into:  1/test_v2/test\\TEST_0181.txt\n",
      "Writting into:  1/test_v2/test\\TEST_0182.txt\n",
      "Writting into:  1/test_v2/test\\TEST_0183.txt\n",
      "Writting into:  1/test_v2/test\\TEST_0184.txt\n",
      "Writting into:  1/test_v2/test\\TEST_0185.txt\n",
      "Writting into:  1/test_v2/test\\TEST_0186.txt\n",
      "Writting into:  1/test_v2/test\\TEST_0187.txt\n",
      "Writting into:  1/test_v2/test\\TEST_0188.txt\n",
      "Writting into:  1/test_v2/test\\TEST_0189.txt\n",
      "Writting into:  1/test_v2/test\\TEST_0190.txt\n",
      "Writting into:  1/test_v2/test\\TEST_0191.txt\n",
      "Writting into:  1/test_v2/test\\TEST_0192.txt\n",
      "Writting into:  1/test_v2/test\\TEST_0193.txt\n",
      "Writting into:  1/test_v2/test\\TEST_0194.txt\n",
      "Writting into:  1/test_v2/test\\TEST_0195.txt\n",
      "Writting into:  1/test_v2/test\\TEST_0196.txt\n",
      "Writting into:  1/test_v2/test\\TEST_0197.txt\n",
      "Writting into:  1/test_v2/test\\TEST_0198.txt\n",
      "Writting into:  1/test_v2/test\\TEST_0199.txt\n",
      "Writting into:  1/test_v2/test\\TEST_0200.txt\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import keras_ocr\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from typing import List\n",
    "\n",
    "def processImagesKerasOcr(imageDirectory, outputDirectory):\n",
    "    pipeline = keras_ocr.pipeline.Pipeline()\n",
    "    \n",
    "    # Get all image files from the folder\n",
    "    imagePaths = []\n",
    "    validExtensions = ('.jpg',  '.png', )\n",
    "    \n",
    "    counter = 0\n",
    "    for filename in os.listdir(imageDirectory):\n",
    "        if counter == 200:\n",
    "            break\n",
    "        if filename.lower().endswith(validExtensions):\n",
    "            print(\"Testing image: \", filename)\n",
    "            imagePaths.append(os.path.join(imageDirectory, filename))\n",
    "        counter += 1\n",
    "    if not imagePaths:\n",
    "        return\n",
    "    \n",
    "    images = [keras_ocr.tools.read(img_path) for img_path in imagePaths]\n",
    "    prediction_groups = pipeline.recognize(images)\n",
    "    \n",
    "    results = []\n",
    "    for predictions in prediction_groups:\n",
    "        text = ' '.join([prediction[0] for prediction in predictions])\n",
    "        results.append(text)\n",
    "\n",
    "    for filename, predictions in zip(imagePaths, prediction_groups):\n",
    "        text = ' '.join([prediction[0] for prediction in predictions])\n",
    "        txt_filename = os.path.splitext(filename)[0] + \".txt\"\n",
    "        txt_filepath = os.path.join(outputDirectory, txt_filename.split(\"\\\\\")[-1])\n",
    "        with open(txt_filepath, \"w\", encoding=\"utf-8\") as txt_file:\n",
    "            print(\"Writting into: \", txt_filepath)\n",
    "            txt_file.write(text)\n",
    "            txt_file.write(text)\n",
    "    return #NEED TO ADD RESULT\n",
    "\n",
    "# Example usage:\n",
    "processImagesKerasOcr(imageNameWritten,'output-name/keras')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "characterLabels = u\"ABCDEFGHIJKLMNOPQRSTUVWXYZ-',. \"\n",
    "lenCharacterLabels = len(characterLabels) + 1\n",
    "maxLen = 32 #NEED TO FIGOURE OUT                WAS 0 BEFORE IDK IF IT IS CORRECT\n",
    "num_of_timestamps = 64\n",
    "def labelNumber(label):\n",
    "    num = []\n",
    "    for i in label:\n",
    "        num.append(characterLabels.find(i))\n",
    "    return np.array(num)\n",
    "\n",
    "def numberLabel(num):\n",
    "    label =\"\"\n",
    "    for i in num:\n",
    "        if i ==-1:\n",
    "            break\n",
    "        else:\n",
    "            label += characterLabels[i]\n",
    "    return label\n",
    "\n",
    "#def  nnumberLabel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True label :  NOUR \n",
      "train_y :  [13. 14. 20. 17. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.\n",
      " -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.] \n",
      "train_label_len :  [4.] \n",
      "train_input_len :  [62.]\n"
     ]
    }
   ],
   "source": [
    "# BEFLOW IS DIFFERENT PAGE\n",
    "train_y = np.ones([trainSize, maxLen]) * -1\n",
    "train_label_len = np.zeros([trainSize, 1])\n",
    "train_input_len = np.ones([trainSize, 1]) * (num_of_timestamps-2)\n",
    "train_output = np.zeros([trainSize])\n",
    "\n",
    "for i in range(trainSize):\n",
    "    train_label_len[i] = len(train.loc[i, 'IDENTITY'])\n",
    "    train_y[i, 0:len(train.loc[i, 'IDENTITY'])]= labelNumber(train.loc[i, 'IDENTITY'])\n",
    "\n",
    "valid_y = np.ones([validateSize, maxLen]) * -1\n",
    "valid_label_len = np.zeros([validateSize, 1])\n",
    "valid_input_len = np.ones([validateSize, 1]) * (num_of_timestamps-2)\n",
    "valid_output = np.zeros([validateSize])\n",
    "\n",
    "for i in range(validateSize):\n",
    "    valid_label_len[i] = len(valid.loc[i, 'IDENTITY'])\n",
    "    valid_y[i, 0:len(valid.loc[i, 'IDENTITY'])]= labelNumber(valid.loc[i, 'IDENTITY'])  \n",
    "print('True label : ',train.loc[100, 'IDENTITY'] , '\\ntrain_y : ',train_y[100],'\\ntrain_label_len : ',train_label_len[100], \n",
    "      '\\ntrain_input_len : ', train_input_len[100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_16\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input (InputLayer)          [(None, 256, 64, 1)]      0         \n",
      "                                                                 \n",
      " conv1 (Conv2D)              (None, 256, 64, 32)       320       \n",
      "                                                                 \n",
      " batch_normalization_3 (Batc  (None, 256, 64, 32)      128       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " activation_4 (Activation)   (None, 256, 64, 32)       0         \n",
      "                                                                 \n",
      " max1 (MaxPooling2D)         (None, 128, 32, 32)       0         \n",
      "                                                                 \n",
      " conv2 (Conv2D)              (None, 128, 32, 64)       18496     \n",
      "                                                                 \n",
      " batch_normalization_4 (Batc  (None, 128, 32, 64)      256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " activation_5 (Activation)   (None, 128, 32, 64)       0         \n",
      "                                                                 \n",
      " max2 (MaxPooling2D)         (None, 64, 16, 64)        0         \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 64, 16, 64)        0         \n",
      "                                                                 \n",
      " conv3 (Conv2D)              (None, 64, 16, 128)       73856     \n",
      "                                                                 \n",
      " batch_normalization_5 (Batc  (None, 64, 16, 128)      512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " activation_6 (Activation)   (None, 64, 16, 128)       0         \n",
      "                                                                 \n",
      " max3 (MaxPooling2D)         (None, 64, 8, 128)        0         \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 64, 8, 128)        0         \n",
      "                                                                 \n",
      " reshape (Reshape)           (None, 64, 1024)          0         \n",
      "                                                                 \n",
      " dense1 (Dense)              (None, 64, 64)            65600     \n",
      "                                                                 \n",
      " lstm1 (Bidirectional)       (None, 64, 512)           657408    \n",
      "                                                                 \n",
      " lstm2 (Bidirectional)       (None, 64, 512)           1574912   \n",
      "                                                                 \n",
      " dense2 (Dense)              (None, 64, 32)            16416     \n",
      "                                                                 \n",
      " softmax (Activation)        (None, 64, 32)            0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,407,904\n",
      "Trainable params: 2,407,456\n",
      "Non-trainable params: 448\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Input, Conv2D, MaxPooling2D, Reshape, Bidirectional, LSTM, Dense, Lambda, Activation, BatchNormalization, Dropout\n",
    "from keras.models import Model\n",
    "\n",
    "input_data = Input(shape=(256, 64, 1), name='input')\n",
    "\n",
    "inner = Conv2D(32, (3, 3), padding='same', name='conv1', kernel_initializer='he_normal')(input_data)  \n",
    "inner = BatchNormalization()(inner)\n",
    "inner = Activation('relu')(inner)\n",
    "inner = MaxPooling2D(pool_size=(2, 2), name='max1')(inner)\n",
    "\n",
    "inner = Conv2D(64, (3, 3), padding='same', name='conv2', kernel_initializer='he_normal')(inner)\n",
    "inner = BatchNormalization()(inner)\n",
    "inner = Activation('relu')(inner)\n",
    "inner = MaxPooling2D(pool_size=(2, 2), name='max2')(inner)\n",
    "inner = Dropout(0.3)(inner)\n",
    "\n",
    "inner = Conv2D(128, (3, 3), padding='same', name='conv3', kernel_initializer='he_normal')(inner)\n",
    "inner = BatchNormalization()(inner)\n",
    "inner = Activation('relu')(inner)\n",
    "inner = MaxPooling2D(pool_size=(1, 2), name='max3')(inner)\n",
    "inner = Dropout(0.3)(inner)\n",
    "\n",
    "#CNN to RNN\n",
    "inner = Reshape(target_shape=((64, 1024)), name='reshape')(inner)\n",
    "inner = Dense(64, activation='relu', kernel_initializer='he_normal', name='dense1')(inner)\n",
    "\n",
    "## RNN\n",
    "inner = Bidirectional(LSTM(256, return_sequences=True), name = 'lstm1')(inner)\n",
    "inner = Bidirectional(LSTM(256, return_sequences=True), name = 'lstm2')(inner)\n",
    "\n",
    "## OUTPUT\n",
    "inner = Dense(lenCharacterLabels, kernel_initializer='he_normal',name='dense2')(inner)\n",
    "y_pred = Activation('softmax', name='softmax')(inner)\n",
    "\n",
    "model = Model(inputs=input_data, outputs=y_pred)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Lambda\n",
    "\n",
    "# the ctc loss function\n",
    "def ctc_lambda_func(args):\n",
    "    y_pred, labels, input_length, label_length = args\n",
    "    # the 2 is critical here since the first couple outputs of the RNN\n",
    "    # tend to be garbage\n",
    "    y_pred = y_pred[:, 2:, :]\n",
    "    return K.ctc_batch_cost(labels, y_pred, input_length, label_length)\n",
    "\n",
    "labels = Input(name='gtruth_labels', shape=[maxLen], dtype='float32')\n",
    "input_length = Input(name='input_length', shape=[1], dtype='int64')\n",
    "label_length = Input(name='label_length', shape=[1], dtype='int64')\n",
    "\n",
    "ctc_loss = Lambda(ctc_lambda_func, output_shape=(1,), name='ctc')([y_pred, labels, input_length, label_length])\n",
    "model_final = Model(inputs=[input_data, labels, input_length, label_length], outputs=ctc_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\adam4\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Data cardinality is ambiguous:\n  x sizes: 1, 25000, 25000, 25000\n  y sizes: 25000\nMake sure all arrays contain the same number of samples.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [72]\u001b[0m, in \u001b[0;36m<cell line: 5>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01moptimizers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Adam\n\u001b[0;32m      3\u001b[0m model_final\u001b[38;5;241m.\u001b[39mcompile(loss\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mctc\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28;01mlambda\u001b[39;00m y_true, y_pred: y_pred}, optimizer\u001b[38;5;241m=\u001b[39mAdam(lr \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0001\u001b[39m))\n\u001b[1;32m----> 5\u001b[0m \u001b[43mmodel_final\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mprepTrainValid\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtrain\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrainSize\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_y\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_input_len\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_label_len\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_output\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[43m                \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mprepTrainValid\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mvalidation\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidateSize\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalid_y\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalid_input_len\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalid_label_len\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalid_output\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[43m                \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m60\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m128\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\adam4\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mc:\\Users\\adam4\\anaconda3\\lib\\site-packages\\keras\\engine\\data_adapter.py:1851\u001b[0m, in \u001b[0;36m_check_data_cardinality\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m   1844\u001b[0m     msg \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m  \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m sizes: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m   1845\u001b[0m         label,\n\u001b[0;32m   1846\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\n\u001b[0;32m   1847\u001b[0m             \u001b[38;5;28mstr\u001b[39m(i\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mnest\u001b[38;5;241m.\u001b[39mflatten(single_data)\n\u001b[0;32m   1848\u001b[0m         ),\n\u001b[0;32m   1849\u001b[0m     )\n\u001b[0;32m   1850\u001b[0m msg \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMake sure all arrays contain the same number of samples.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1851\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n",
      "\u001b[1;31mValueError\u001b[0m: Data cardinality is ambiguous:\n  x sizes: 1, 25000, 25000, 25000\n  y sizes: 25000\nMake sure all arrays contain the same number of samples."
     ]
    }
   ],
   "source": [
    "from keras.optimizers import Adam\n",
    "\n",
    "model_final.compile(loss={'ctc': lambda y_true, y_pred: y_pred}, optimizer=Adam(lr = 0.0001))\n",
    "\n",
    "model_final.fit(x=[prepTrainValid('train', trainSize), train_y, train_input_len, train_label_len], y=train_output, \n",
    "                validation_data=([prepTrainValid('validation', validateSize), valid_y, valid_input_len, valid_label_len], valid_output),\n",
    "                epochs=60, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_15\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " image_input (InputLayer)    [(None, 256, 64, 1)]      0         \n",
      "                                                                 \n",
      " conv2d_18 (Conv2D)          (None, 256, 64, 64)       640       \n",
      "                                                                 \n",
      " max_pooling2d_16 (MaxPoolin  (None, 128, 32, 64)      0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_19 (Conv2D)          (None, 128, 32, 128)      73856     \n",
      "                                                                 \n",
      " max_pooling2d_17 (MaxPoolin  (None, 64, 16, 128)      0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " reshape_8 (Reshape)         (None, 32, 4096)          0         \n",
      "                                                                 \n",
      " bidirectional_16 (Bidirecti  (None, 32, 256)          4326400   \n",
      " onal)                                                           \n",
      "                                                                 \n",
      " bidirectional_17 (Bidirecti  (None, 32, 256)          394240    \n",
      " onal)                                                           \n",
      "                                                                 \n",
      " output (Dense)              (None, 32, 64)            16448     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4,811,584\n",
      "Trainable params: 4,811,584\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Reshape, Dense, LSTM, Bidirectional\n",
    "from tensorflow.keras.models import Model\n",
    "import tensorflow.keras.backend as K\n",
    "from keras.layers import Activation\n",
    "\n",
    "# Define model architecture\n",
    "def build_model(img_shape=(256, 64, 1), maxLen=32):\n",
    "    inputs = Input(shape=img_shape, name=\"image_input\")\n",
    "\n",
    "\n",
    "    #INSPO FROM GOOGLE COLLAB\n",
    "    # CNN Feature Extractor\n",
    "    x = Conv2D(64, (3,3), activation='relu', padding='same')(inputs)\n",
    "    x = MaxPooling2D(pool_size=(2,2))(x)\n",
    "    x = Conv2D(128, (3,3), activation='relu', padding='same')(x)\n",
    "    x = MaxPooling2D(pool_size=(2,2))(x)\n",
    "\n",
    "    # Reshape for RNN\n",
    "    x = Reshape(target_shape=(32, -1))(x)\n",
    "\n",
    "    # RNN Encoder\n",
    "    x = Bidirectional(LSTM(128, return_sequences=True))(x)\n",
    "    x = Bidirectional(LSTM(128, return_sequences=True))(x)\n",
    "\n",
    "    # Output layer\n",
    "    x = Dense(64, activation=\"softmax\", name=\"output\")(x)\n",
    "    outputs = Activation('softmax', name='softmax')(x)\n",
    "\n",
    "    model = Model(inputs, outputs)\n",
    "    return model, outputs\n",
    "\n",
    "# Build model\n",
    "model = build_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 0), (388, 0), (388, 20), (0, 20)]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20, 388, 3)\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def getBoundingBox(image_path):\n",
    "    image = cv2.imread(image_path)\n",
    "\n",
    "    # Convert image to grayscale\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Get word-level bounding boxes\n",
    "    data = pytesseract.image_to_data(gray, output_type=pytesseract.Output.DICT)\n",
    "\n",
    "    allBox = []\n",
    "    x_min, y_min, x_max, y_max = float('inf'), float('inf'), 0, 0\n",
    "\n",
    "    # Loop through detected words\n",
    "    for i in range(len(data['text'])):\n",
    "        if data['text'][i].strip():  # Ignore empty text\n",
    "            x, y, w, h = data['left'][i], data['top'][i], data['width'][i], data['height'][i]\n",
    "            \n",
    "            # Compute full bounding box limits\n",
    "            x_min = min(x_min, x)\n",
    "            y_min = min(y_min, y)\n",
    "            x_max = max(x_max, x + w)\n",
    "            y_max = max(y_max, y + h)\n",
    "            # Store individual word bounding box\n",
    "            #temp = [(x, y), (x + w, y), (x + w, y + h), (x, y + h)]\n",
    "            #allBox.append(temp)\n",
    "\n",
    "            # Draw individual word bounding box\n",
    "            #cv2.rectangle(image, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "            #cv2.putText(image, data['text'][i], (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 1)\n",
    "        \n",
    "    #Use whole image to avoid inf (data already cleaned)\n",
    "    if x_min == float('inf') or y_min == float('inf'):\n",
    "        #    print(\"No text detected! Using full image as bounding box.\")\n",
    "            x_min, y_min = 0, 0\n",
    "            y_max, x_max = image.shape[:2]  # height, width\n",
    "    full_bbox = [(x_min, y_min), (x_max, y_min), (x_max, y_max), (x_min, y_max)]\n",
    "    \n",
    "    # Draw single full bounding box\n",
    "    cv2.rectangle(image, (x_min, y_min), (x_max, y_max), (0, 0, 255), 2)\n",
    "\n",
    "    return image, allBox, full_bbox\n",
    "\n",
    "\n",
    "image, boxes, full_bbox= getBoundingBox(\"1/train_v2/train/TRAIN_00007.jpg\")\n",
    "print(full_bbox)\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.imshow(image)\n",
    "plt.axis(\"off\")  # Hide axes\n",
    "plt.show()\n",
    "print(image.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/train_v2/train/TRAIN_00001.jpg\n",
      "1/train_v2/train/TRAIN_00002.jpg\n",
      "1/validation_v2/validation/VALIDATION_0001.jpg\n",
      "1/test_v2/test/TEST_0001.jpg\n"
     ]
    }
   ],
   "source": [
    "def get_dataset_from_df(df, image_folder, limit):\n",
    "    dataset = []\n",
    "    i = 0\n",
    "    for _, row in df.iterrows():\n",
    "        if limit == i :\n",
    "            break\n",
    "        image_name = row['FILENAME']  # Assuming the column is named 'filename'\n",
    "        text = row['IDENTITY']  # Assuming the column is named 'text'\n",
    "        \n",
    "        # Construct the full image path\n",
    "        image_path = image_folder+\"/\"+ image_name\n",
    "        print(image_path)\n",
    "        img, allBBox, BBox =getBoundingBox(image_path)\n",
    "        dataset.append((image_path, {\"lines\": [{\"text\": text, \"vertices\": BBox}]}))\n",
    "        i += 1\n",
    "    return dataset\n",
    "\n",
    "train_dataset = get_dataset_from_df(train, '1/train_v2/train', 2)\n",
    "val_dataset = get_dataset_from_df(valid, '1/validation_v2/validation', 1)\n",
    "test_dataset = get_dataset_from_df(test, '1/test_v2/test', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('1/train_v2/train/TRAIN_00001.jpg', {'lines': [{'text': 'BALTHAZAR', 'vertices': [(30, 10), (163, 10), (163, 43), (30, 43)]}]}), ('1/train_v2/train/TRAIN_00002.jpg', {'lines': [{'text': 'SIMON', 'vertices': [(30, 5), (104, 5), (104, 56), (30, 56)]}]})]\n",
      "[('1/validation_v2/validation/VALIDATION_0001.jpg', {'lines': [{'text': 'BILEL', 'vertices': [(22, 7), (94, 7), (94, 22), (22, 22)]}]})]\n",
      "[('1/test_v2/test/TEST_0001.jpg', {'lines': [{'text': 'KEVIN', 'vertices': [(25, 6), (91, 6), (91, 22), (25, 22)]}]})]\n"
     ]
    }
   ],
   "source": [
    "print(train_dataset)\n",
    "print(val_dataset)\n",
    "print(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8.9\n",
      "c:\\Users\\adam4\\anaconda3\\lib\\site-packages\\keras_ocr\\__init__.py\n"
     ]
    }
   ],
   "source": [
    "# In Jupyter/Colab:%pip uninstall -y keras-ocr\n",
    "#%pip install keras-ocr==0.8.9\n",
    "import keras_ocr\n",
    "print(keras_ocr.__version__)\n",
    "print(keras_ocr.__file__)  # This reveals the problematic path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('1/train_v2/train/TRAIN_00001.jpg', 'BALTHAZAR'), ('1/train_v2/train/TRAIN_00002.jpg', 'SIMON'), ('1/train_v2/train/TRAIN_00003.jpg', 'BENES'), ('1/train_v2/train/TRAIN_00004.jpg', 'LA LOVE'), ('1/train_v2/train/TRAIN_00005.jpg', 'DAPHNE'), ('1/train_v2/train/TRAIN_00006.jpg', 'LUCIE'), ('1/train_v2/train/TRAIN_00007.jpg', 'NASSIM'), ('1/train_v2/train/TRAIN_00008.jpg', 'ASSRAOUI'), ('1/train_v2/train/TRAIN_00009.jpg', 'LAVIAN'), ('1/train_v2/train/TRAIN_00010.jpg', 'MAEVA'), ('1/train_v2/train/TRAIN_00011.jpg', 'EMMA'), ('1/train_v2/train/TRAIN_00012.jpg', 'MOULINIER'), ('1/train_v2/train/TRAIN_00013.jpg', 'ELISE'), ('1/train_v2/train/TRAIN_00014.jpg', 'HONNERT'), ('1/train_v2/train/TRAIN_00015.jpg', 'MATHEO'), ('1/train_v2/train/TRAIN_00016.jpg', 'PETITDIDIER'), ('1/train_v2/train/TRAIN_00017.jpg', 'PAULINE'), ('1/train_v2/train/TRAIN_00018.jpg', 'LOUVENAZ'), ('1/train_v2/train/TRAIN_00019.jpg', 'BOURQUIN'), ('1/train_v2/train/TRAIN_00020.jpg', 'ROMAIN'), ('1/train_v2/train/TRAIN_00021.jpg', 'ASMA'), ('1/train_v2/train/TRAIN_00022.jpg', 'CYRIELLE'), ('1/train_v2/train/TRAIN_00023.jpg', 'LILOU'), ('1/train_v2/train/TRAIN_00024.jpg', 'ESTEBANN'), ('1/train_v2/train/TRAIN_00025.jpg', 'MITHIEUX'), ('1/train_v2/train/TRAIN_00026.jpg', 'MARION'), ('1/train_v2/train/TRAIN_00027.jpg', 'THOMAS'), ('1/train_v2/train/TRAIN_00028.jpg', 'ANAIS'), ('1/train_v2/train/TRAIN_00029.jpg', 'BROLL'), ('1/train_v2/train/TRAIN_00030.jpg', 'JAFFEUX'), ('1/train_v2/train/TRAIN_00031.jpg', 'ANNE'), ('1/train_v2/train/TRAIN_00032.jpg', 'PREVOST'), ('1/train_v2/train/TRAIN_00033.jpg', 'ROMANE'), ('1/train_v2/train/TRAIN_00034.jpg', 'BRUGERIE'), ('1/train_v2/train/TRAIN_00035.jpg', 'NOLAN'), ('1/train_v2/train/TRAIN_00036.jpg', 'LORENTIN'), ('1/train_v2/train/TRAIN_00037.jpg', 'ELISA'), ('1/train_v2/train/TRAIN_00038.jpg', 'PAULINE'), ('1/train_v2/train/TRAIN_00039.jpg', 'FRANCOIS'), ('1/train_v2/train/TRAIN_00040.jpg', 'MAUPAS'), ('1/train_v2/train/TRAIN_00041.jpg', 'MEISSA'), ('1/train_v2/train/TRAIN_00042.jpg', 'REBACH'), ('1/train_v2/train/TRAIN_00043.jpg', 'ERWAN'), ('1/train_v2/train/TRAIN_00044.jpg', 'AMBROISE'), ('1/train_v2/train/TRAIN_00045.jpg', 'LAURA'), ('1/train_v2/train/TRAIN_00046.jpg', 'AHMED-KHODJA'), ('1/train_v2/train/TRAIN_00047.jpg', 'LOISE'), ('1/train_v2/train/TRAIN_00048.jpg', 'ELBAKKALI'), ('1/train_v2/train/TRAIN_00049.jpg', 'BENZINA'), ('1/train_v2/train/TRAIN_00050.jpg', 'LAQUERRIERE'), ('1/train_v2/train/TRAIN_00051.jpg', 'YAEL'), ('1/train_v2/train/TRAIN_00052.jpg', 'VITRE'), ('1/train_v2/train/TRAIN_00053.jpg', 'GUILLOT GOGUET'), ('1/train_v2/train/TRAIN_00054.jpg', 'BOLOZAN'), ('1/train_v2/train/TRAIN_00055.jpg', 'MATHEO'), ('1/train_v2/train/TRAIN_00056.jpg', 'SHA I'), ('1/train_v2/train/TRAIN_00057.jpg', 'VICTORIA'), ('1/train_v2/train/TRAIN_00058.jpg', 'JULIE'), ('1/train_v2/train/TRAIN_00059.jpg', 'BARBIER'), ('1/train_v2/train/TRAIN_00060.jpg', 'GILLES-LAWRENCE'), ('1/train_v2/train/TRAIN_00061.jpg', 'DUPRAT'), ('1/train_v2/train/TRAIN_00062.jpg', 'LABARH'), ('1/train_v2/train/TRAIN_00063.jpg', 'REMI'), ('1/train_v2/train/TRAIN_00064.jpg', 'BLANLO'), ('1/train_v2/train/TRAIN_00065.jpg', 'ARGITXU'), ('1/train_v2/train/TRAIN_00066.jpg', 'SINEM'), ('1/train_v2/train/TRAIN_00067.jpg', 'LISON'), ('1/train_v2/train/TRAIN_00068.jpg', 'PAYEN-MERLE'), ('1/train_v2/train/TRAIN_00069.jpg', 'INES'), ('1/train_v2/train/TRAIN_00070.jpg', 'NAWFEL'), ('1/train_v2/train/TRAIN_00071.jpg', 'WADSWORRE'), ('1/train_v2/train/TRAIN_00072.jpg', 'CROCHARD'), ('1/train_v2/train/TRAIN_00073.jpg', 'FREDERIC'), ('1/train_v2/train/TRAIN_00074.jpg', 'RODRIGUES'), ('1/train_v2/train/TRAIN_00075.jpg', 'AUBANE'), ('1/train_v2/train/TRAIN_00076.jpg', 'ELISA'), ('1/train_v2/train/TRAIN_00077.jpg', 'ACHOURI'), ('1/train_v2/train/TRAIN_00078.jpg', 'MAEVA'), ('1/train_v2/train/TRAIN_00079.jpg', 'GRINAND'), ('1/train_v2/train/TRAIN_00080.jpg', 'ANTOINE'), ('1/train_v2/train/TRAIN_00081.jpg', 'SANA'), ('1/train_v2/train/TRAIN_00082.jpg', 'ENZO'), ('1/train_v2/train/TRAIN_00083.jpg', 'DOMAS'), ('1/train_v2/train/TRAIN_00084.jpg', 'MALOLEPSZY'), ('1/train_v2/train/TRAIN_00085.jpg', 'THOMAS'), ('1/train_v2/train/TRAIN_00086.jpg', 'JULIE'), ('1/train_v2/train/TRAIN_00087.jpg', 'KADIR EREN'), ('1/train_v2/train/TRAIN_00088.jpg', 'PERIOL'), ('1/train_v2/train/TRAIN_00089.jpg', 'BGUGEAU'), ('1/train_v2/train/TRAIN_00090.jpg', 'SOCHET'), ('1/train_v2/train/TRAIN_00091.jpg', 'TROUVAT'), ('1/train_v2/train/TRAIN_00092.jpg', 'GARGUEB'), ('1/train_v2/train/TRAIN_00093.jpg', 'CORALIE'), ('1/train_v2/train/TRAIN_00094.jpg', 'VANDENABEELE'), ('1/train_v2/train/TRAIN_00095.jpg', 'TEZKRAT'), ('1/train_v2/train/TRAIN_00096.jpg', 'ASHLEY'), ('1/train_v2/train/TRAIN_00097.jpg', 'CAGNARD'), ('1/train_v2/train/TRAIN_00098.jpg', 'SANOGO'), ('1/train_v2/train/TRAIN_00099.jpg', 'AMBROSS'), ('1/train_v2/train/TRAIN_00100.jpg', 'GAROT'), ('1/train_v2/train/TRAIN_00101.jpg', 'NOUR'), ('1/train_v2/train/TRAIN_00102.jpg', 'TIMOTHEE'), ('1/train_v2/train/TRAIN_00103.jpg', 'MILIANI-THIBA'), ('1/train_v2/train/TRAIN_00104.jpg', 'THEO'), ('1/train_v2/train/TRAIN_00105.jpg', 'GOURDELIER'), ('1/train_v2/train/TRAIN_00106.jpg', 'VINCENT'), ('1/train_v2/train/TRAIN_00107.jpg', 'WILLOQUAUX'), ('1/train_v2/train/TRAIN_00108.jpg', 'LOVIS'), ('1/train_v2/train/TRAIN_00109.jpg', 'VERSTRAETE'), ('1/train_v2/train/TRAIN_00110.jpg', 'SINDI'), ('1/train_v2/train/TRAIN_00111.jpg', 'LUC'), ('1/train_v2/train/TRAIN_00112.jpg', 'EMMA'), ('1/train_v2/train/TRAIN_00113.jpg', 'DERVAUX'), ('1/train_v2/train/TRAIN_00114.jpg', 'GUILLO'), ('1/train_v2/train/TRAIN_00115.jpg', 'MEUDIER'), ('1/train_v2/train/TRAIN_00116.jpg', 'COLLIN'), ('1/train_v2/train/TRAIN_00117.jpg', 'MACKER'), ('1/train_v2/train/TRAIN_00118.jpg', 'RAPHAEL'), ('1/train_v2/train/TRAIN_00119.jpg', 'FERON'), ('1/train_v2/train/TRAIN_00120.jpg', 'DAUMESNIL'), ('1/train_v2/train/TRAIN_00121.jpg', 'VINCENT'), ('1/train_v2/train/TRAIN_00122.jpg', 'BOUTET'), ('1/train_v2/train/TRAIN_00123.jpg', 'BERNARD'), ('1/train_v2/train/TRAIN_00124.jpg', 'BENLAHSEN'), ('1/train_v2/train/TRAIN_00125.jpg', 'COSSA'), ('1/train_v2/train/TRAIN_00126.jpg', 'BELOEIL'), ('1/train_v2/train/TRAIN_00127.jpg', 'MARTINS'), ('1/train_v2/train/TRAIN_00128.jpg', 'RAYANE'), ('1/train_v2/train/TRAIN_00129.jpg', 'BRACONNIER'), ('1/train_v2/train/TRAIN_00130.jpg', 'ANDREA'), ('1/train_v2/train/TRAIN_00131.jpg', 'BOEUF'), ('1/train_v2/train/TRAIN_00132.jpg', 'BAPTISTE'), ('1/train_v2/train/TRAIN_00133.jpg', 'CHRUSCIEL'), ('1/train_v2/train/TRAIN_00134.jpg', 'JAUREGUIBERRY'), ('1/train_v2/train/TRAIN_00135.jpg', 'SATDANI'), ('1/train_v2/train/TRAIN_00136.jpg', 'VINCOTTE'), ('1/train_v2/train/TRAIN_00137.jpg', 'NAIT SIDI AHMED'), ('1/train_v2/train/TRAIN_00138.jpg', 'JANATI'), ('1/train_v2/train/TRAIN_00139.jpg', 'GARRIDO'), ('1/train_v2/train/TRAIN_00140.jpg', 'BENSAIS RUEDA'), ('1/train_v2/train/TRAIN_00141.jpg', 'ULA'), ('1/train_v2/train/TRAIN_00142.jpg', 'LUC'), ('1/train_v2/train/TRAIN_00143.jpg', 'GARCIA'), ('1/train_v2/train/TRAIN_00144.jpg', 'GENIQUE-ENNIS'), ('1/train_v2/train/TRAIN_00145.jpg', 'OCEANE'), ('1/train_v2/train/TRAIN_00146.jpg', 'ALEXANDRE'), ('1/train_v2/train/TRAIN_00147.jpg', 'MALTET'), ('1/train_v2/train/TRAIN_00148.jpg', 'PEREZ'), ('1/train_v2/train/TRAIN_00149.jpg', 'LEGRANCHE'), ('1/train_v2/train/TRAIN_00150.jpg', 'ROMANE'), ('1/train_v2/train/TRAIN_00151.jpg', 'ANDRE'), ('1/train_v2/train/TRAIN_00152.jpg', 'LILI'), ('1/train_v2/train/TRAIN_00153.jpg', 'RICK'), ('1/train_v2/train/TRAIN_00154.jpg', 'ORLANNE'), ('1/train_v2/train/TRAIN_00155.jpg', 'EWEN'), ('1/train_v2/train/TRAIN_00156.jpg', 'BOGLARKA'), ('1/train_v2/train/TRAIN_00157.jpg', 'GUST'), ('1/train_v2/train/TRAIN_00158.jpg', 'LIUUT'), ('1/train_v2/train/TRAIN_00159.jpg', 'DJAVID'), ('1/train_v2/train/TRAIN_00160.jpg', 'MARGAUX'), ('1/train_v2/train/TRAIN_00161.jpg', 'DHULU'), ('1/train_v2/train/TRAIN_00162.jpg', 'CADWAL'), ('1/train_v2/train/TRAIN_00163.jpg', 'WATTIEZ'), ('1/train_v2/train/TRAIN_00164.jpg', 'CORDON'), ('1/train_v2/train/TRAIN_00165.jpg', 'QUENTIN'), ('1/train_v2/train/TRAIN_00166.jpg', 'RAYAN'), ('1/train_v2/train/TRAIN_00167.jpg', 'THOMAS'), ('1/train_v2/train/TRAIN_00168.jpg', 'CUCHERIL'), ('1/train_v2/train/TRAIN_00169.jpg', 'LOUIS'), ('1/train_v2/train/TRAIN_00170.jpg', 'ELINE'), ('1/train_v2/train/TRAIN_00171.jpg', 'ARTHUR'), ('1/train_v2/train/TRAIN_00172.jpg', 'GUEDJ'), ('1/train_v2/train/TRAIN_00173.jpg', 'FONTAINE'), ('1/train_v2/train/TRAIN_00174.jpg', 'SIMEON'), ('1/train_v2/train/TRAIN_00175.jpg', 'GARCIA'), ('1/train_v2/train/TRAIN_00176.jpg', 'LEGRAND'), ('1/train_v2/train/TRAIN_00177.jpg', 'CORENTIN'), ('1/train_v2/train/TRAIN_00178.jpg', 'MARIE'), ('1/train_v2/train/TRAIN_00179.jpg', 'ENATH'), ('1/train_v2/train/TRAIN_00180.jpg', 'EMMA'), ('1/train_v2/train/TRAIN_00181.jpg', 'MOLDE'), ('1/train_v2/train/TRAIN_00182.jpg', 'CHARLOTTE'), ('1/train_v2/train/TRAIN_00183.jpg', 'CAMILLE'), ('1/train_v2/train/TRAIN_00184.jpg', 'MAILLET'), ('1/train_v2/train/TRAIN_00185.jpg', 'MAUNIER'), ('1/train_v2/train/TRAIN_00186.jpg', 'REBECCA'), ('1/train_v2/train/TRAIN_00187.jpg', 'TRISTAN'), ('1/train_v2/train/TRAIN_00188.jpg', 'TAIVEL'), ('1/train_v2/train/TRAIN_00189.jpg', 'BENJAMIN'), ('1/train_v2/train/TRAIN_00190.jpg', 'RODRIGUEZ'), ('1/train_v2/train/TRAIN_00191.jpg', 'GILLE'), ('1/train_v2/train/TRAIN_00192.jpg', 'PIBOURRET'), ('1/train_v2/train/TRAIN_00193.jpg', 'HAJJI'), ('1/train_v2/train/TRAIN_00194.jpg', 'LINE'), ('1/train_v2/train/TRAIN_00195.jpg', 'REYNAL'), ('1/train_v2/train/TRAIN_00196.jpg', 'NATHAN'), ('1/train_v2/train/TRAIN_00197.jpg', 'CROENNE'), ('1/train_v2/train/TRAIN_00198.jpg', 'ILLANA'), ('1/train_v2/train/TRAIN_00199.jpg', 'AGNUS'), ('1/train_v2/train/TRAIN_00200.jpg', 'ROMAIN'), ('1/train_v2/train/TRAIN_00201.jpg', 'EVAN'), ('1/train_v2/train/TRAIN_00202.jpg', 'LILOU'), ('1/train_v2/train/TRAIN_00203.jpg', 'MATHIS'), ('1/train_v2/train/TRAIN_00204.jpg', 'KHELOUL'), ('1/train_v2/train/TRAIN_00205.jpg', 'YOCOUBI'), ('1/train_v2/train/TRAIN_00206.jpg', 'COLINE'), ('1/train_v2/train/TRAIN_00207.jpg', 'MELIA'), ('1/train_v2/train/TRAIN_00208.jpg', 'FUZELU'), ('1/train_v2/train/TRAIN_00209.jpg', 'ROUES'), ('1/train_v2/train/TRAIN_00210.jpg', 'MAXIME'), ('1/train_v2/train/TRAIN_00211.jpg', 'GIBAJA'), ('1/train_v2/train/TRAIN_00212.jpg', 'DAVID'), ('1/train_v2/train/TRAIN_00213.jpg', 'MAELYS'), ('1/train_v2/train/TRAIN_00214.jpg', 'ROBERT'), ('1/train_v2/train/TRAIN_00215.jpg', 'SACHA'), ('1/train_v2/train/TRAIN_00216.jpg', 'ELOISE'), ('1/train_v2/train/TRAIN_00217.jpg', 'CONSTANT'), ('1/train_v2/train/TRAIN_00218.jpg', 'AMAL'), ('1/train_v2/train/TRAIN_00219.jpg', 'AMELIE'), ('1/train_v2/train/TRAIN_00220.jpg', 'DYLAN'), ('1/train_v2/train/TRAIN_00221.jpg', 'COUDOUR'), ('1/train_v2/train/TRAIN_00222.jpg', 'CAER'), ('1/train_v2/train/TRAIN_00223.jpg', 'UGO'), ('1/train_v2/train/TRAIN_00224.jpg', 'FLORA'), ('1/train_v2/train/TRAIN_00225.jpg', 'ELOAN'), ('1/train_v2/train/TRAIN_00226.jpg', 'KADDAR'), ('1/train_v2/train/TRAIN_00227.jpg', 'KECIAN'), ('1/train_v2/train/TRAIN_00228.jpg', 'HUDON'), ('1/train_v2/train/TRAIN_00229.jpg', 'BUTEUX'), ('1/train_v2/train/TRAIN_00230.jpg', 'DUAULT'), ('1/train_v2/train/TRAIN_00231.jpg', 'BENITO'), ('1/train_v2/train/TRAIN_00232.jpg', 'VERENE'), ('1/train_v2/train/TRAIN_00233.jpg', 'MAILI'), ('1/train_v2/train/TRAIN_00234.jpg', 'BROSSARD'), ('1/train_v2/train/TRAIN_00235.jpg', 'GWENOLA'), ('1/train_v2/train/TRAIN_00236.jpg', 'PEREIRA'), ('1/train_v2/train/TRAIN_00237.jpg', 'MONICA'), ('1/train_v2/train/TRAIN_00238.jpg', 'EMELINE'), ('1/train_v2/train/TRAIN_00239.jpg', 'TANGUY'), ('1/train_v2/train/TRAIN_00240.jpg', 'MATHIEU'), ('1/train_v2/train/TRAIN_00241.jpg', 'RAPHAELLE'), ('1/train_v2/train/TRAIN_00242.jpg', 'MATTEO'), ('1/train_v2/train/TRAIN_00243.jpg', 'LEA'), ('1/train_v2/train/TRAIN_00244.jpg', 'REDWAN'), ('1/train_v2/train/TRAIN_00245.jpg', 'CAROLANE'), ('1/train_v2/train/TRAIN_00246.jpg', 'EDGAR'), ('1/train_v2/train/TRAIN_00247.jpg', 'EMPTY'), ('1/train_v2/train/TRAIN_00248.jpg', 'DUHOUX'), ('1/train_v2/train/TRAIN_00249.jpg', 'CLEMENT-GAUTIER'), ('1/train_v2/train/TRAIN_00250.jpg', 'WANDA'), ('1/train_v2/train/TRAIN_00251.jpg', 'THOMAS'), ('1/train_v2/train/TRAIN_00252.jpg', 'SAGEAUX'), ('1/train_v2/train/TRAIN_00253.jpg', 'OSCAR'), ('1/train_v2/train/TRAIN_00254.jpg', 'SARAH'), ('1/train_v2/train/TRAIN_00255.jpg', 'SUEDA'), ('1/train_v2/train/TRAIN_00256.jpg', 'GAUTHIER'), ('1/train_v2/train/TRAIN_00257.jpg', 'CLARA'), ('1/train_v2/train/TRAIN_00258.jpg', 'JOUI'), ('1/train_v2/train/TRAIN_00259.jpg', 'GUILHEM'), ('1/train_v2/train/TRAIN_00260.jpg', \"LE'DU\"), ('1/train_v2/train/TRAIN_00261.jpg', 'REZKALLAN'), ('1/train_v2/train/TRAIN_00262.jpg', 'YOHAN'), ('1/train_v2/train/TRAIN_00263.jpg', 'KLARA'), ('1/train_v2/train/TRAIN_00264.jpg', 'LESSEUR'), ('1/train_v2/train/TRAIN_00265.jpg', 'BENKHEROUF'), ('1/train_v2/train/TRAIN_00266.jpg', 'PERAINE'), ('1/train_v2/train/TRAIN_00267.jpg', 'REDA'), ('1/train_v2/train/TRAIN_00268.jpg', 'COLIN'), ('1/train_v2/train/TRAIN_00269.jpg', 'HENEUVRIER'), ('1/train_v2/train/TRAIN_00270.jpg', 'UGO'), ('1/train_v2/train/TRAIN_00271.jpg', 'AVRIL'), ('1/train_v2/train/TRAIN_00272.jpg', 'CRESPIN'), ('1/train_v2/train/TRAIN_00273.jpg', 'DEMONGEOT'), ('1/train_v2/train/TRAIN_00274.jpg', 'HELENE'), ('1/train_v2/train/TRAIN_00275.jpg', 'CHARLOTTE'), ('1/train_v2/train/TRAIN_00276.jpg', 'QUEHERE'), ('1/train_v2/train/TRAIN_00277.jpg', 'GANOO'), ('1/train_v2/train/TRAIN_00278.jpg', 'LOUIS'), ('1/train_v2/train/TRAIN_00279.jpg', 'MARGAUX'), ('1/train_v2/train/TRAIN_00280.jpg', 'DYLAN'), ('1/train_v2/train/TRAIN_00281.jpg', 'BERGEAULT'), ('1/train_v2/train/TRAIN_00282.jpg', 'MALIA'), ('1/train_v2/train/TRAIN_00283.jpg', 'GUILLEMETTE'), ('1/train_v2/train/TRAIN_00284.jpg', 'HUGO'), ('1/train_v2/train/TRAIN_00285.jpg', 'GAVETTI'), ('1/train_v2/train/TRAIN_00286.jpg', 'ARTHUR'), ('1/train_v2/train/TRAIN_00287.jpg', 'FLORE'), ('1/train_v2/train/TRAIN_00288.jpg', 'LE GOALLER'), ('1/train_v2/train/TRAIN_00289.jpg', 'LOUISE'), ('1/train_v2/train/TRAIN_00290.jpg', 'VICTOR'), ('1/train_v2/train/TRAIN_00291.jpg', 'RAMERINI'), ('1/train_v2/train/TRAIN_00292.jpg', 'SAUVAGE'), ('1/train_v2/train/TRAIN_00293.jpg', 'MAUD'), ('1/train_v2/train/TRAIN_00294.jpg', 'SIMON'), ('1/train_v2/train/TRAIN_00295.jpg', 'GORIN'), ('1/train_v2/train/TRAIN_00296.jpg', 'THIRION'), ('1/train_v2/train/TRAIN_00297.jpg', 'COULIS'), ('1/train_v2/train/TRAIN_00298.jpg', 'MARRISA'), ('1/train_v2/train/TRAIN_00299.jpg', 'ARADJ'), ('1/train_v2/train/TRAIN_00300.jpg', 'CHLOE'), ('1/train_v2/train/TRAIN_00301.jpg', 'TOURY'), ('1/train_v2/train/TRAIN_00302.jpg', 'FLORA'), ('1/train_v2/train/TRAIN_00303.jpg', 'CHARLOTTE'), ('1/train_v2/train/TRAIN_00304.jpg', 'AYMERICH'), ('1/train_v2/train/TRAIN_00305.jpg', 'YOUCEF'), ('1/train_v2/train/TRAIN_00306.jpg', 'ARIANE'), ('1/train_v2/train/TRAIN_00307.jpg', 'DUROCHAT'), ('1/train_v2/train/TRAIN_00308.jpg', 'GEFFROY'), ('1/train_v2/train/TRAIN_00309.jpg', 'RAZAKARIVELO'), ('1/train_v2/train/TRAIN_00310.jpg', 'GUERRIER'), ('1/train_v2/train/TRAIN_00311.jpg', 'NOEL'), ('1/train_v2/train/TRAIN_00312.jpg', 'BOUILLAUD'), ('1/train_v2/train/TRAIN_00313.jpg', 'ELISIA'), ('1/train_v2/train/TRAIN_00314.jpg', 'HUGO'), ('1/train_v2/train/TRAIN_00315.jpg', 'PLANTARD'), ('1/train_v2/train/TRAIN_00316.jpg', 'YANG'), ('1/train_v2/train/TRAIN_00317.jpg', 'MAXENCE'), ('1/train_v2/train/TRAIN_00318.jpg', 'LUNA'), ('1/train_v2/train/TRAIN_00319.jpg', 'SASHA'), ('1/train_v2/train/TRAIN_00320.jpg', 'LIPPENS'), ('1/train_v2/train/TRAIN_00321.jpg', 'JULIE'), ('1/train_v2/train/TRAIN_00322.jpg', 'TRISTAN'), ('1/train_v2/train/TRAIN_00323.jpg', 'BONNIE'), ('1/train_v2/train/TRAIN_00324.jpg', 'DELONGEAS'), ('1/train_v2/train/TRAIN_00325.jpg', 'PINEAU'), ('1/train_v2/train/TRAIN_00326.jpg', 'PLICHON'), ('1/train_v2/train/TRAIN_00327.jpg', 'NOHANED-ALI'), ('1/train_v2/train/TRAIN_00328.jpg', 'TONY'), ('1/train_v2/train/TRAIN_00329.jpg', 'RHITHAN'), ('1/train_v2/train/TRAIN_00330.jpg', 'RUGNTER'), ('1/train_v2/train/TRAIN_00331.jpg', 'ZOHRA'), ('1/train_v2/train/TRAIN_00332.jpg', 'THELMA'), ('1/train_v2/train/TRAIN_00333.jpg', 'NAVE'), ('1/train_v2/train/TRAIN_00334.jpg', 'OVIZE'), ('1/train_v2/train/TRAIN_00335.jpg', 'DE ARAUJO'), ('1/train_v2/train/TRAIN_00336.jpg', 'LEA'), ('1/train_v2/train/TRAIN_00337.jpg', 'MOKHTAR-DIDOUCHE'), ('1/train_v2/train/TRAIN_00338.jpg', 'GUILLET'), ('1/train_v2/train/TRAIN_00339.jpg', 'COUMES'), ('1/train_v2/train/TRAIN_00340.jpg', 'BENNOURA'), ('1/train_v2/train/TRAIN_00341.jpg', 'ALIX'), ('1/train_v2/train/TRAIN_00342.jpg', 'FLAVIE'), ('1/train_v2/train/TRAIN_00343.jpg', 'GROLLEAU'), ('1/train_v2/train/TRAIN_00344.jpg', 'BRILLET'), ('1/train_v2/train/TRAIN_00345.jpg', 'NUGUE'), ('1/train_v2/train/TRAIN_00346.jpg', 'BONNEFOUX'), ('1/train_v2/train/TRAIN_00347.jpg', 'ARTHUR'), ('1/train_v2/train/TRAIN_00348.jpg', 'HODE'), ('1/train_v2/train/TRAIN_00349.jpg', 'ANAIS'), ('1/train_v2/train/TRAIN_00350.jpg', 'CASSANDRA'), ('1/train_v2/train/TRAIN_00351.jpg', 'GUILHEM'), ('1/train_v2/train/TRAIN_00352.jpg', 'JUNIOR'), ('1/train_v2/train/TRAIN_00353.jpg', 'TUIGI'), ('1/train_v2/train/TRAIN_00354.jpg', 'SOLENE'), ('1/train_v2/train/TRAIN_00355.jpg', 'ELINA'), ('1/train_v2/train/TRAIN_00356.jpg', 'FRANCOIS'), ('1/train_v2/train/TRAIN_00357.jpg', 'CHARTRIN'), ('1/train_v2/train/TRAIN_00358.jpg', 'SIMON'), ('1/train_v2/train/TRAIN_00359.jpg', 'PAUL'), ('1/train_v2/train/TRAIN_00360.jpg', 'JOSUE'), ('1/train_v2/train/TRAIN_00361.jpg', 'MATISSE'), ('1/train_v2/train/TRAIN_00362.jpg', 'SCHELL'), ('1/train_v2/train/TRAIN_00363.jpg', 'ALIZEE'), ('1/train_v2/train/TRAIN_00364.jpg', 'CELIA'), ('1/train_v2/train/TRAIN_00365.jpg', 'THEO'), ('1/train_v2/train/TRAIN_00366.jpg', 'PIETRUSZEWSKI'), ('1/train_v2/train/TRAIN_00367.jpg', 'BESSIERE'), ('1/train_v2/train/TRAIN_00368.jpg', 'ADRIEW'), ('1/train_v2/train/TRAIN_00369.jpg', 'POLLET'), ('1/train_v2/train/TRAIN_00370.jpg', 'ALBIN'), ('1/train_v2/train/TRAIN_00371.jpg', 'MIHAI'), ('1/train_v2/train/TRAIN_00372.jpg', 'COLIN'), ('1/train_v2/train/TRAIN_00373.jpg', 'MARGAUY'), ('1/train_v2/train/TRAIN_00374.jpg', 'DANON'), ('1/train_v2/train/TRAIN_00375.jpg', 'ANAELLE'), ('1/train_v2/train/TRAIN_00376.jpg', 'HEDI'), ('1/train_v2/train/TRAIN_00377.jpg', 'LE DUS'), ('1/train_v2/train/TRAIN_00378.jpg', 'HASSON'), ('1/train_v2/train/TRAIN_00379.jpg', 'LILIAN'), ('1/train_v2/train/TRAIN_00380.jpg', 'MARTIN'), ('1/train_v2/train/TRAIN_00381.jpg', 'THCO'), ('1/train_v2/train/TRAIN_00382.jpg', 'KAYMAK'), ('1/train_v2/train/TRAIN_00383.jpg', 'LECAUDE'), ('1/train_v2/train/TRAIN_00384.jpg', 'TANAIS'), ('1/train_v2/train/TRAIN_00385.jpg', 'BRACQUEMART'), ('1/train_v2/train/TRAIN_00386.jpg', 'LEO'), ('1/train_v2/train/TRAIN_00387.jpg', 'CHARLOTTE'), ('1/train_v2/train/TRAIN_00388.jpg', 'VAWRZYNIAK'), ('1/train_v2/train/TRAIN_00389.jpg', 'KAISER'), ('1/train_v2/train/TRAIN_00390.jpg', 'MATHIEU'), ('1/train_v2/train/TRAIN_00391.jpg', 'DORIDANT'), ('1/train_v2/train/TRAIN_00392.jpg', 'LIN'), ('1/train_v2/train/TRAIN_00393.jpg', 'MVOU DELORME'), ('1/train_v2/train/TRAIN_00394.jpg', 'CONDE-LAVALETTE'), ('1/train_v2/train/TRAIN_00395.jpg', 'ALYSSA'), ('1/train_v2/train/TRAIN_00396.jpg', 'DUGNOLLE'), ('1/train_v2/train/TRAIN_00397.jpg', 'BORDELET'), ('1/train_v2/train/TRAIN_00398.jpg', 'CAMILLE'), ('1/train_v2/train/TRAIN_00399.jpg', 'APOLLINE'), ('1/train_v2/train/TRAIN_00400.jpg', 'GUEMART'), ('1/train_v2/train/TRAIN_00401.jpg', 'CALOEE'), ('1/train_v2/train/TRAIN_00402.jpg', 'YAVO'), ('1/train_v2/train/TRAIN_00403.jpg', 'PERES'), ('1/train_v2/train/TRAIN_00404.jpg', 'ARTHUR'), ('1/train_v2/train/TRAIN_00405.jpg', 'ADRIEN'), ('1/train_v2/train/TRAIN_00406.jpg', 'AGNESA'), ('1/train_v2/train/TRAIN_00407.jpg', 'TEA'), ('1/train_v2/train/TRAIN_00408.jpg', 'PERRIER'), ('1/train_v2/train/TRAIN_00409.jpg', 'MENAGER'), ('1/train_v2/train/TRAIN_00410.jpg', 'GABIN'), ('1/train_v2/train/TRAIN_00411.jpg', 'CLARA'), ('1/train_v2/train/TRAIN_00412.jpg', 'LAUMET'), ('1/train_v2/train/TRAIN_00413.jpg', 'DUSSAIGNE RAPHAEL'), ('1/train_v2/train/TRAIN_00414.jpg', 'AUDE'), ('1/train_v2/train/TRAIN_00415.jpg', 'AZMANI'), ('1/train_v2/train/TRAIN_00416.jpg', 'KIMELIE'), ('1/train_v2/train/TRAIN_00417.jpg', 'MUGO'), ('1/train_v2/train/TRAIN_00418.jpg', 'MATHIS'), ('1/train_v2/train/TRAIN_00419.jpg', 'BERARD'), ('1/train_v2/train/TRAIN_00420.jpg', 'LUCIE'), ('1/train_v2/train/TRAIN_00421.jpg', 'BRUGEROLLE'), ('1/train_v2/train/TRAIN_00422.jpg', 'GAITI'), ('1/train_v2/train/TRAIN_00423.jpg', 'THEO'), ('1/train_v2/train/TRAIN_00424.jpg', 'PIGUET'), ('1/train_v2/train/TRAIN_00425.jpg', 'JAUBERT'), ('1/train_v2/train/TRAIN_00426.jpg', 'QUEMTIN'), ('1/train_v2/train/TRAIN_00427.jpg', 'ANTOINE'), ('1/train_v2/train/TRAIN_00428.jpg', 'BEBON'), ('1/train_v2/train/TRAIN_00429.jpg', 'AXELLE'), ('1/train_v2/train/TRAIN_00430.jpg', 'MAURICE'), ('1/train_v2/train/TRAIN_00431.jpg', 'BOURLES'), ('1/train_v2/train/TRAIN_00432.jpg', 'MAELLE'), ('1/train_v2/train/TRAIN_00433.jpg', 'TITOUAN'), ('1/train_v2/train/TRAIN_00434.jpg', 'LUCILE'), ('1/train_v2/train/TRAIN_00435.jpg', 'MARC-ANTOINE'), ('1/train_v2/train/TRAIN_00436.jpg', 'HARCHAND'), ('1/train_v2/train/TRAIN_00437.jpg', 'BRITNEY'), ('1/train_v2/train/TRAIN_00438.jpg', 'NATHAN'), ('1/train_v2/train/TRAIN_00439.jpg', 'HOLLEVILLE'), ('1/train_v2/train/TRAIN_00440.jpg', 'YOU'), ('1/train_v2/train/TRAIN_00441.jpg', 'CLARA'), ('1/train_v2/train/TRAIN_00442.jpg', 'FEMIET'), ('1/train_v2/train/TRAIN_00443.jpg', 'ANAIS'), ('1/train_v2/train/TRAIN_00444.jpg', 'CORBET'), ('1/train_v2/train/TRAIN_00445.jpg', 'FROSIO'), ('1/train_v2/train/TRAIN_00446.jpg', 'INACIO'), ('1/train_v2/train/TRAIN_00447.jpg', 'CAMILLE'), ('1/train_v2/train/TRAIN_00448.jpg', 'SIMON'), ('1/train_v2/train/TRAIN_00449.jpg', 'HAMZAOUI'), ('1/train_v2/train/TRAIN_00450.jpg', 'BAUDOUIN'), ('1/train_v2/train/TRAIN_00451.jpg', 'CHIRINE'), ('1/train_v2/train/TRAIN_00452.jpg', 'LINHART'), ('1/train_v2/train/TRAIN_00453.jpg', 'FAYARD'), ('1/train_v2/train/TRAIN_00454.jpg', 'MERAT'), ('1/train_v2/train/TRAIN_00455.jpg', 'KHELOUFI'), ('1/train_v2/train/TRAIN_00456.jpg', 'CHLOE'), ('1/train_v2/train/TRAIN_00457.jpg', 'BASTIEN'), ('1/train_v2/train/TRAIN_00458.jpg', 'JEANNE'), ('1/train_v2/train/TRAIN_00459.jpg', 'NOEMIE'), ('1/train_v2/train/TRAIN_00460.jpg', 'GILLETTE'), ('1/train_v2/train/TRAIN_00461.jpg', 'BLONDEAU'), ('1/train_v2/train/TRAIN_00462.jpg', 'BOUQUE'), ('1/train_v2/train/TRAIN_00463.jpg', 'LINDSAY'), ('1/train_v2/train/TRAIN_00464.jpg', 'DERET'), ('1/train_v2/train/TRAIN_00465.jpg', 'DURAND'), ('1/train_v2/train/TRAIN_00466.jpg', 'CHRISTOPHE'), ('1/train_v2/train/TRAIN_00467.jpg', 'BAISSIERES'), ('1/train_v2/train/TRAIN_00468.jpg', 'MATHYS'), ('1/train_v2/train/TRAIN_00469.jpg', 'TURBE'), ('1/train_v2/train/TRAIN_00470.jpg', 'LEVRIER'), ('1/train_v2/train/TRAIN_00471.jpg', 'PAUL'), ('1/train_v2/train/TRAIN_00472.jpg', 'YANN'), ('1/train_v2/train/TRAIN_00473.jpg', 'LIM'), ('1/train_v2/train/TRAIN_00474.jpg', 'BEHUET'), ('1/train_v2/train/TRAIN_00475.jpg', 'SY'), ('1/train_v2/train/TRAIN_00476.jpg', 'BREGEARD'), ('1/train_v2/train/TRAIN_00477.jpg', 'KELLIAN'), ('1/train_v2/train/TRAIN_00478.jpg', 'EMPTY'), ('1/train_v2/train/TRAIN_00479.jpg', 'DEBAILLEUL'), ('1/train_v2/train/TRAIN_00480.jpg', 'HANX'), ('1/train_v2/train/TRAIN_00481.jpg', 'LOUSTALOT'), ('1/train_v2/train/TRAIN_00482.jpg', 'TARDITI'), ('1/train_v2/train/TRAIN_00483.jpg', 'RYANE'), ('1/train_v2/train/TRAIN_00484.jpg', 'JEREMY'), ('1/train_v2/train/TRAIN_00485.jpg', 'BARAT'), ('1/train_v2/train/TRAIN_00486.jpg', 'GREGOIRE'), ('1/train_v2/train/TRAIN_00487.jpg', 'MARION'), ('1/train_v2/train/TRAIN_00488.jpg', 'TRISTAN'), ('1/train_v2/train/TRAIN_00489.jpg', 'MONTAGNE'), ('1/train_v2/train/TRAIN_00490.jpg', 'UTILLE'), ('1/train_v2/train/TRAIN_00491.jpg', 'LOUIS-LOUP'), ('1/train_v2/train/TRAIN_00492.jpg', 'ALARCON'), ('1/train_v2/train/TRAIN_00493.jpg', 'FLAVIE'), ('1/train_v2/train/TRAIN_00494.jpg', 'MASSON'), ('1/train_v2/train/TRAIN_00495.jpg', 'AURELIEN'), ('1/train_v2/train/TRAIN_00496.jpg', 'KYLIAN'), ('1/train_v2/train/TRAIN_00497.jpg', 'MATTEO'), ('1/train_v2/train/TRAIN_00498.jpg', 'ENZO'), ('1/train_v2/train/TRAIN_00499.jpg', 'VALENTIN'), ('1/train_v2/train/TRAIN_00500.jpg', 'GDULSKI'), ('1/train_v2/train/TRAIN_00501.jpg', 'ALESSANDRO'), ('1/train_v2/train/TRAIN_00502.jpg', 'KOMAROFF'), ('1/train_v2/train/TRAIN_00503.jpg', 'NOEMIE'), ('1/train_v2/train/TRAIN_00504.jpg', 'LOUIS'), ('1/train_v2/train/TRAIN_00505.jpg', 'GAUTIER'), ('1/train_v2/train/TRAIN_00506.jpg', 'BEN MOHAND'), ('1/train_v2/train/TRAIN_00507.jpg', 'MANON'), ('1/train_v2/train/TRAIN_00508.jpg', 'TALON'), ('1/train_v2/train/TRAIN_00509.jpg', 'DE GENOUILLAC'), ('1/train_v2/train/TRAIN_00510.jpg', 'DUMOULIN'), ('1/train_v2/train/TRAIN_00511.jpg', 'HENRI'), ('1/train_v2/train/TRAIN_00512.jpg', 'PLANCHARD'), ('1/train_v2/train/TRAIN_00513.jpg', 'LACROIX'), ('1/train_v2/train/TRAIN_00514.jpg', 'GEYER'), ('1/train_v2/train/TRAIN_00515.jpg', 'VOLPI'), ('1/train_v2/train/TRAIN_00516.jpg', 'FLORENT'), ('1/train_v2/train/TRAIN_00517.jpg', 'CHLOE'), ('1/train_v2/train/TRAIN_00518.jpg', 'RAYAN'), ('1/train_v2/train/TRAIN_00519.jpg', 'HASSIBI'), ('1/train_v2/train/TRAIN_00520.jpg', 'NGUER'), ('1/train_v2/train/TRAIN_00521.jpg', 'MAOUACHE'), ('1/train_v2/train/TRAIN_00522.jpg', 'MARDY'), ('1/train_v2/train/TRAIN_00523.jpg', 'DURAND'), ('1/train_v2/train/TRAIN_00524.jpg', 'CLEMENCE'), ('1/train_v2/train/TRAIN_00525.jpg', 'ANTHONY'), ('1/train_v2/train/TRAIN_00526.jpg', 'CLEMENT'), ('1/train_v2/train/TRAIN_00527.jpg', 'LOUCIB'), ('1/train_v2/train/TRAIN_00528.jpg', 'HELOISE'), ('1/train_v2/train/TRAIN_00529.jpg', 'ESSE'), ('1/train_v2/train/TRAIN_00530.jpg', 'ELISE'), ('1/train_v2/train/TRAIN_00531.jpg', 'CATRY'), ('1/train_v2/train/TRAIN_00532.jpg', 'KEDDAR'), ('1/train_v2/train/TRAIN_00533.jpg', 'BEGUE'), ('1/train_v2/train/TRAIN_00534.jpg', 'SOLAL'), ('1/train_v2/train/TRAIN_00535.jpg', 'FANT'), ('1/train_v2/train/TRAIN_00536.jpg', 'DEBBLASI'), ('1/train_v2/train/TRAIN_00537.jpg', 'NONE'), ('1/train_v2/train/TRAIN_00538.jpg', 'MARIE'), ('1/train_v2/train/TRAIN_00539.jpg', 'LAURA'), ('1/train_v2/train/TRAIN_00540.jpg', 'TIABIA'), ('1/train_v2/train/TRAIN_00541.jpg', 'CHEVEREAU'), ('1/train_v2/train/TRAIN_00542.jpg', 'YOUSSEF'), ('1/train_v2/train/TRAIN_00543.jpg', 'KAOUTAR'), ('1/train_v2/train/TRAIN_00544.jpg', 'POIO'), ('1/train_v2/train/TRAIN_00545.jpg', 'CROUZET-VIVIEN'), ('1/train_v2/train/TRAIN_00546.jpg', 'NONE'), ('1/train_v2/train/TRAIN_00547.jpg', 'LOUIS'), ('1/train_v2/train/TRAIN_00548.jpg', 'MAX'), ('1/train_v2/train/TRAIN_00549.jpg', 'LEGRAND'), ('1/train_v2/train/TRAIN_00550.jpg', 'ALEXANDRE'), ('1/train_v2/train/TRAIN_00551.jpg', 'NAOFEL'), ('1/train_v2/train/TRAIN_00552.jpg', 'NGONDI'), ('1/train_v2/train/TRAIN_00553.jpg', 'CAREO-JOBERT'), ('1/train_v2/train/TRAIN_00554.jpg', 'LOUIS'), ('1/train_v2/train/TRAIN_00555.jpg', 'BRION'), ('1/train_v2/train/TRAIN_00556.jpg', 'BACHELARD'), ('1/train_v2/train/TRAIN_00557.jpg', 'HALBELAID'), ('1/train_v2/train/TRAIN_00558.jpg', 'LUBET'), ('1/train_v2/train/TRAIN_00559.jpg', 'GUIDICELLI'), ('1/train_v2/train/TRAIN_00560.jpg', 'AUGUSTIN'), ('1/train_v2/train/TRAIN_00561.jpg', 'LUCAS'), ('1/train_v2/train/TRAIN_00562.jpg', 'BOUSTIE'), ('1/train_v2/train/TRAIN_00563.jpg', 'LYDIA'), ('1/train_v2/train/TRAIN_00564.jpg', 'HYLENE'), ('1/train_v2/train/TRAIN_00565.jpg', 'FISCHER'), ('1/train_v2/train/TRAIN_00566.jpg', 'SELEN'), ('1/train_v2/train/TRAIN_00567.jpg', 'ALEXANDRE'), ('1/train_v2/train/TRAIN_00568.jpg', 'CHAMBRON'), ('1/train_v2/train/TRAIN_00569.jpg', 'MARAL'), ('1/train_v2/train/TRAIN_00570.jpg', 'YASSIN'), ('1/train_v2/train/TRAIN_00571.jpg', 'REMY'), ('1/train_v2/train/TRAIN_00572.jpg', 'CARESMEL'), ('1/train_v2/train/TRAIN_00573.jpg', 'CYPRIEN'), ('1/train_v2/train/TRAIN_00574.jpg', 'ALEXIS'), ('1/train_v2/train/TRAIN_00575.jpg', 'CLERQUIN'), ('1/train_v2/train/TRAIN_00576.jpg', 'MANON'), ('1/train_v2/train/TRAIN_00577.jpg', 'SEGUELA'), ('1/train_v2/train/TRAIN_00578.jpg', 'BEENAZIEZ'), ('1/train_v2/train/TRAIN_00579.jpg', 'COTTINET'), ('1/train_v2/train/TRAIN_00580.jpg', 'JEU'), ('1/train_v2/train/TRAIN_00581.jpg', 'KOCH'), ('1/train_v2/train/TRAIN_00582.jpg', 'RAMSEYER'), ('1/train_v2/train/TRAIN_00583.jpg', 'CHAMPION'), ('1/train_v2/train/TRAIN_00584.jpg', 'MANON'), ('1/train_v2/train/TRAIN_00585.jpg', 'PERROS'), ('1/train_v2/train/TRAIN_00586.jpg', 'CHAMPION'), ('1/train_v2/train/TRAIN_00587.jpg', 'ALISON'), ('1/train_v2/train/TRAIN_00588.jpg', 'BOULADE'), ('1/train_v2/train/TRAIN_00589.jpg', 'ARLIN'), ('1/train_v2/train/TRAIN_00590.jpg', 'DARENN'), ('1/train_v2/train/TRAIN_00591.jpg', 'GUERIN'), ('1/train_v2/train/TRAIN_00592.jpg', 'QUENTIN'), ('1/train_v2/train/TRAIN_00593.jpg', 'HUGO'), ('1/train_v2/train/TRAIN_00594.jpg', 'IMANE'), ('1/train_v2/train/TRAIN_00595.jpg', 'EMMA'), ('1/train_v2/train/TRAIN_00596.jpg', 'AURIANE'), ('1/train_v2/train/TRAIN_00597.jpg', 'SERVE'), ('1/train_v2/train/TRAIN_00598.jpg', 'MARION'), ('1/train_v2/train/TRAIN_00599.jpg', 'LUCAS'), ('1/train_v2/train/TRAIN_00600.jpg', 'JULIETTE'), ('1/train_v2/train/TRAIN_00601.jpg', 'DROINEAU'), ('1/train_v2/train/TRAIN_00602.jpg', 'MARVIN'), ('1/train_v2/train/TRAIN_00603.jpg', 'ROY'), ('1/train_v2/train/TRAIN_00604.jpg', 'MATHEO'), ('1/train_v2/train/TRAIN_00605.jpg', 'PAULINE'), ('1/train_v2/train/TRAIN_00606.jpg', 'BORIES'), ('1/train_v2/train/TRAIN_00607.jpg', 'ROUMENGOU'), ('1/train_v2/train/TRAIN_00608.jpg', 'ZIELENSKI'), ('1/train_v2/train/TRAIN_00609.jpg', 'DELRUE'), ('1/train_v2/train/TRAIN_00610.jpg', 'SINEAD'), ('1/train_v2/train/TRAIN_00611.jpg', 'CROIZAT'), ('1/train_v2/train/TRAIN_00612.jpg', 'ZIELENSKY'), ('1/train_v2/train/TRAIN_00613.jpg', 'ASAITIE'), ('1/train_v2/train/TRAIN_00614.jpg', 'PAULINE'), ('1/train_v2/train/TRAIN_00615.jpg', 'GOUDARD'), ('1/train_v2/train/TRAIN_00616.jpg', 'TOURESSE'), ('1/train_v2/train/TRAIN_00617.jpg', 'ERIKA'), ('1/train_v2/train/TRAIN_00618.jpg', 'ELSA'), ('1/train_v2/train/TRAIN_00619.jpg', 'KOURISNA'), ('1/train_v2/train/TRAIN_00620.jpg', 'LISE'), ('1/train_v2/train/TRAIN_00621.jpg', 'DIALUNGANA'), ('1/train_v2/train/TRAIN_00622.jpg', 'COMBE'), ('1/train_v2/train/TRAIN_00623.jpg', 'LIEGLER'), ('1/train_v2/train/TRAIN_00624.jpg', 'NOURDIN'), ('1/train_v2/train/TRAIN_00625.jpg', 'MAATI'), ('1/train_v2/train/TRAIN_00626.jpg', 'JOSSE'), ('1/train_v2/train/TRAIN_00627.jpg', 'MEUNIER'), ('1/train_v2/train/TRAIN_00628.jpg', 'BENJAMIN'), ('1/train_v2/train/TRAIN_00629.jpg', 'DELMAIRE'), ('1/train_v2/train/TRAIN_00630.jpg', 'GWEGUEN'), ('1/train_v2/train/TRAIN_00631.jpg', 'SARAH'), ('1/train_v2/train/TRAIN_00632.jpg', 'FRANZ-LEONARD'), ('1/train_v2/train/TRAIN_00633.jpg', 'TEIXEIRA'), ('1/train_v2/train/TRAIN_00634.jpg', 'SACHA'), ('1/train_v2/train/TRAIN_00635.jpg', 'DALLI'), ('1/train_v2/train/TRAIN_00636.jpg', 'GEORGES'), ('1/train_v2/train/TRAIN_00637.jpg', 'FLORA'), ('1/train_v2/train/TRAIN_00638.jpg', 'BRIOT'), ('1/train_v2/train/TRAIN_00639.jpg', 'PILLON'), ('1/train_v2/train/TRAIN_00640.jpg', 'MORARD'), ('1/train_v2/train/TRAIN_00641.jpg', 'ARHUR'), ('1/train_v2/train/TRAIN_00642.jpg', 'THIBAULT'), ('1/train_v2/train/TRAIN_00643.jpg', 'FAUGUE'), ('1/train_v2/train/TRAIN_00644.jpg', 'RAFAEL'), ('1/train_v2/train/TRAIN_00645.jpg', 'LE PAGE'), ('1/train_v2/train/TRAIN_00646.jpg', 'LEOGLONNEC'), ('1/train_v2/train/TRAIN_00647.jpg', 'MFUIDIMAU'), ('1/train_v2/train/TRAIN_00648.jpg', 'BAROUKH'), ('1/train_v2/train/TRAIN_00649.jpg', 'CLEMENCE'), ('1/train_v2/train/TRAIN_00650.jpg', 'SHARON'), ('1/train_v2/train/TRAIN_00651.jpg', 'LECLERE'), ('1/train_v2/train/TRAIN_00652.jpg', 'DUFEY'), ('1/train_v2/train/TRAIN_00653.jpg', 'EVAN'), ('1/train_v2/train/TRAIN_00654.jpg', 'HUGO'), ('1/train_v2/train/TRAIN_00655.jpg', 'NICOLEY'), ('1/train_v2/train/TRAIN_00656.jpg', 'FERCHECHE'), ('1/train_v2/train/TRAIN_00657.jpg', 'ROOSE'), ('1/train_v2/train/TRAIN_00658.jpg', 'BORSON'), ('1/train_v2/train/TRAIN_00659.jpg', 'AZHERIC'), ('1/train_v2/train/TRAIN_00660.jpg', 'FELIX'), ('1/train_v2/train/TRAIN_00661.jpg', 'HUET'), ('1/train_v2/train/TRAIN_00662.jpg', 'MAXIME'), ('1/train_v2/train/TRAIN_00663.jpg', 'POILVET'), ('1/train_v2/train/TRAIN_00664.jpg', 'MAYLINE'), ('1/train_v2/train/TRAIN_00665.jpg', 'KHETTOUP KACI'), ('1/train_v2/train/TRAIN_00666.jpg', 'CHAVOT'), ('1/train_v2/train/TRAIN_00667.jpg', 'BENJAMIN'), ('1/train_v2/train/TRAIN_00668.jpg', 'CELIA'), ('1/train_v2/train/TRAIN_00669.jpg', 'LODATO'), ('1/train_v2/train/TRAIN_00670.jpg', 'MAXIME'), ('1/train_v2/train/TRAIN_00671.jpg', 'MOREL'), ('1/train_v2/train/TRAIN_00672.jpg', 'EVENAS'), ('1/train_v2/train/TRAIN_00673.jpg', 'ROMANE'), ('1/train_v2/train/TRAIN_00674.jpg', 'LEA'), ('1/train_v2/train/TRAIN_00675.jpg', 'MARTIN'), ('1/train_v2/train/TRAIN_00676.jpg', 'ILLIAMHAJIUA'), ('1/train_v2/train/TRAIN_00677.jpg', 'NOVAILLES'), ('1/train_v2/train/TRAIN_00678.jpg', 'MARGAUX'), ('1/train_v2/train/TRAIN_00679.jpg', 'MUSIAL'), ('1/train_v2/train/TRAIN_00680.jpg', 'CHARLES'), ('1/train_v2/train/TRAIN_00681.jpg', 'BASTIEN'), ('1/train_v2/train/TRAIN_00682.jpg', 'ROMAIN'), ('1/train_v2/train/TRAIN_00683.jpg', 'SANA'), ('1/train_v2/train/TRAIN_00684.jpg', 'DEJESUSTEIXEIRA'), ('1/train_v2/train/TRAIN_00685.jpg', 'HAVOUNIA-KOUKA'), ('1/train_v2/train/TRAIN_00686.jpg', 'FATIH'), ('1/train_v2/train/TRAIN_00687.jpg', 'TATIANA'), ('1/train_v2/train/TRAIN_00688.jpg', 'GUILLONNET'), ('1/train_v2/train/TRAIN_00689.jpg', 'VATEL'), ('1/train_v2/train/TRAIN_00690.jpg', 'CORENTIN'), ('1/train_v2/train/TRAIN_00691.jpg', 'ELOISE'), ('1/train_v2/train/TRAIN_00692.jpg', 'HELAL'), ('1/train_v2/train/TRAIN_00693.jpg', 'BERANGERE'), ('1/train_v2/train/TRAIN_00694.jpg', 'BEMOULBLED'), ('1/train_v2/train/TRAIN_00695.jpg', 'LI'), ('1/train_v2/train/TRAIN_00696.jpg', 'LONG'), ('1/train_v2/train/TRAIN_00697.jpg', 'PIERRE'), ('1/train_v2/train/TRAIN_00698.jpg', 'LUCAS'), ('1/train_v2/train/TRAIN_00699.jpg', 'LARRIEU'), ('1/train_v2/train/TRAIN_00700.jpg', 'JADE'), ('1/train_v2/train/TRAIN_00701.jpg', 'NORINE'), ('1/train_v2/train/TRAIN_00702.jpg', 'GREGOIRE'), ('1/train_v2/train/TRAIN_00703.jpg', 'ANTOINE'), ('1/train_v2/train/TRAIN_00704.jpg', 'SOPIANE'), ('1/train_v2/train/TRAIN_00705.jpg', 'GIRARDET'), ('1/train_v2/train/TRAIN_00706.jpg', 'VALENTIN'), ('1/train_v2/train/TRAIN_00707.jpg', 'MAXENCE'), ('1/train_v2/train/TRAIN_00708.jpg', 'SULTANI'), ('1/train_v2/train/TRAIN_00709.jpg', 'POEGARD'), ('1/train_v2/train/TRAIN_00710.jpg', 'MANON'), ('1/train_v2/train/TRAIN_00711.jpg', 'IMENE'), ('1/train_v2/train/TRAIN_00712.jpg', 'VERLEYCN'), ('1/train_v2/train/TRAIN_00713.jpg', 'PIERRE'), ('1/train_v2/train/TRAIN_00714.jpg', 'DUCULTY'), ('1/train_v2/train/TRAIN_00715.jpg', 'MIRANA'), ('1/train_v2/train/TRAIN_00716.jpg', 'EMMA'), ('1/train_v2/train/TRAIN_00717.jpg', 'ALEXANDRE'), ('1/train_v2/train/TRAIN_00718.jpg', 'BOUILLON'), ('1/train_v2/train/TRAIN_00719.jpg', 'JULIE'), ('1/train_v2/train/TRAIN_00720.jpg', 'ALBAN'), ('1/train_v2/train/TRAIN_00721.jpg', 'ROMAIN'), ('1/train_v2/train/TRAIN_00722.jpg', 'ARTUR'), ('1/train_v2/train/TRAIN_00723.jpg', 'BREGEO'), ('1/train_v2/train/TRAIN_00724.jpg', 'PUES'), ('1/train_v2/train/TRAIN_00725.jpg', 'DESSEVRE'), ('1/train_v2/train/TRAIN_00726.jpg', 'JANE'), ('1/train_v2/train/TRAIN_00727.jpg', 'CORALIE'), ('1/train_v2/train/TRAIN_00728.jpg', 'TAILLEFER'), ('1/train_v2/train/TRAIN_00729.jpg', 'ALEXANDRE'), ('1/train_v2/train/TRAIN_00730.jpg', 'EVEDJI'), ('1/train_v2/train/TRAIN_00731.jpg', 'LUCILLE'), ('1/train_v2/train/TRAIN_00732.jpg', 'SEREMY'), ('1/train_v2/train/TRAIN_00733.jpg', 'ESTEBAN'), ('1/train_v2/train/TRAIN_00734.jpg', 'MEHDI'), ('1/train_v2/train/TRAIN_00735.jpg', 'RAPHAEL'), ('1/train_v2/train/TRAIN_00736.jpg', 'ANANDINE'), ('1/train_v2/train/TRAIN_00737.jpg', 'CHLOE'), ('1/train_v2/train/TRAIN_00738.jpg', 'SIAD'), ('1/train_v2/train/TRAIN_00739.jpg', 'LEA'), ('1/train_v2/train/TRAIN_00740.jpg', 'VALENTIN'), ('1/train_v2/train/TRAIN_00741.jpg', 'TOUIL'), ('1/train_v2/train/TRAIN_00742.jpg', 'VERISSI'), ('1/train_v2/train/TRAIN_00743.jpg', 'HERBRETEAU'), ('1/train_v2/train/TRAIN_00744.jpg', 'LECLERCA'), ('1/train_v2/train/TRAIN_00745.jpg', 'CECILE'), ('1/train_v2/train/TRAIN_00746.jpg', 'PEETERMANS'), ('1/train_v2/train/TRAIN_00747.jpg', 'PAPOT'), ('1/train_v2/train/TRAIN_00748.jpg', 'ADELYS'), ('1/train_v2/train/TRAIN_00749.jpg', 'BRIAN'), ('1/train_v2/train/TRAIN_00750.jpg', 'FIGIEL'), ('1/train_v2/train/TRAIN_00751.jpg', 'HAZGUI'), ('1/train_v2/train/TRAIN_00752.jpg', 'LEGOUPIL'), ('1/train_v2/train/TRAIN_00753.jpg', 'CORBELLINI'), ('1/train_v2/train/TRAIN_00754.jpg', 'ALANI BINANI'), ('1/train_v2/train/TRAIN_00755.jpg', 'PESCE'), ('1/train_v2/train/TRAIN_00756.jpg', 'YANN'), ('1/train_v2/train/TRAIN_00757.jpg', 'LOU'), ('1/train_v2/train/TRAIN_00758.jpg', 'APER'), ('1/train_v2/train/TRAIN_00759.jpg', 'SEMAR'), ('1/train_v2/train/TRAIN_00760.jpg', 'VICTOR'), ('1/train_v2/train/TRAIN_00761.jpg', 'MORBU'), ('1/train_v2/train/TRAIN_00762.jpg', 'LOU'), ('1/train_v2/train/TRAIN_00763.jpg', 'AUGUSTE'), ('1/train_v2/train/TRAIN_00764.jpg', 'TAVOREL'), ('1/train_v2/train/TRAIN_00765.jpg', 'CHAPELLIER'), ('1/train_v2/train/TRAIN_00766.jpg', 'NATHAN'), ('1/train_v2/train/TRAIN_00767.jpg', 'GUERAISCHE'), ('1/train_v2/train/TRAIN_00768.jpg', 'LECONFF'), ('1/train_v2/train/TRAIN_00769.jpg', 'REY'), ('1/train_v2/train/TRAIN_00770.jpg', 'MATTHIEO'), ('1/train_v2/train/TRAIN_00771.jpg', 'CORENTIN'), ('1/train_v2/train/TRAIN_00772.jpg', 'SARAGOSLI'), ('1/train_v2/train/TRAIN_00773.jpg', 'NESET'), ('1/train_v2/train/TRAIN_00774.jpg', 'BELBACHIR'), ('1/train_v2/train/TRAIN_00775.jpg', 'WITTMANN'), ('1/train_v2/train/TRAIN_00776.jpg', 'ELOUARD'), ('1/train_v2/train/TRAIN_00777.jpg', 'PAULINE'), ('1/train_v2/train/TRAIN_00778.jpg', 'GUIBERT'), ('1/train_v2/train/TRAIN_00779.jpg', 'HOUL'), ('1/train_v2/train/TRAIN_00780.jpg', 'KYLIAN'), ('1/train_v2/train/TRAIN_00781.jpg', 'ETIEVE'), ('1/train_v2/train/TRAIN_00782.jpg', 'NATHAN'), ('1/train_v2/train/TRAIN_00783.jpg', 'VASSAL'), ('1/train_v2/train/TRAIN_00784.jpg', 'KYLIAN'), ('1/train_v2/train/TRAIN_00785.jpg', 'HUGO'), ('1/train_v2/train/TRAIN_00786.jpg', 'ALLOING'), ('1/train_v2/train/TRAIN_00787.jpg', 'BROCNIER'), ('1/train_v2/train/TRAIN_00788.jpg', 'BACHELOT'), ('1/train_v2/train/TRAIN_00789.jpg', 'DE MONTILLET'), ('1/train_v2/train/TRAIN_00790.jpg', 'GUILLAUME'), ('1/train_v2/train/TRAIN_00791.jpg', 'MALAURY'), ('1/train_v2/train/TRAIN_00792.jpg', 'RAFINI-GAUBERT'), ('1/train_v2/train/TRAIN_00793.jpg', 'CONSTANT'), ('1/train_v2/train/TRAIN_00794.jpg', 'VISIEDO'), ('1/train_v2/train/TRAIN_00795.jpg', 'MELISSA'), ('1/train_v2/train/TRAIN_00796.jpg', 'SEGUINEAU'), ('1/train_v2/train/TRAIN_00797.jpg', 'MORISSEAU'), ('1/train_v2/train/TRAIN_00798.jpg', 'DIARRA'), ('1/train_v2/train/TRAIN_00799.jpg', 'CONSTANT'), ('1/train_v2/train/TRAIN_00800.jpg', 'LAMPE')]\n",
      "[('1/validation_v2/validation/VALIDATION_0001.jpg', 'BILEL'), ('1/validation_v2/validation/VALIDATION_0002.jpg', 'LAUMIONIER'), ('1/validation_v2/validation/VALIDATION_0003.jpg', 'LEA'), ('1/validation_v2/validation/VALIDATION_0004.jpg', 'JEAN-ROCH'), ('1/validation_v2/validation/VALIDATION_0005.jpg', 'RUPP'), ('1/validation_v2/validation/VALIDATION_0007.jpg', 'PICHON'), ('1/validation_v2/validation/VALIDATION_0008.jpg', 'DANIEL'), ('1/validation_v2/validation/VALIDATION_0009.jpg', 'JEREMY'), ('1/validation_v2/validation/VALIDATION_0010.jpg', 'JEAN-MICHEL'), ('1/validation_v2/validation/VALIDATION_0011.jpg', 'JULIEN'), ('1/validation_v2/validation/VALIDATION_0012.jpg', 'NAEL'), ('1/validation_v2/validation/VALIDATION_0013.jpg', 'BILGER'), ('1/validation_v2/validation/VALIDATION_0014.jpg', 'TIFFANY'), ('1/validation_v2/validation/VALIDATION_0015.jpg', 'ELEEN'), ('1/validation_v2/validation/VALIDATION_0016.jpg', 'ANTOINE'), ('1/validation_v2/validation/VALIDATION_0017.jpg', 'AYOUB'), ('1/validation_v2/validation/VALIDATION_0018.jpg', 'MINETTE'), ('1/validation_v2/validation/VALIDATION_0019.jpg', 'RAINGEVAL'), ('1/validation_v2/validation/VALIDATION_0020.jpg', 'CELESTIN'), ('1/validation_v2/validation/VALIDATION_0021.jpg', 'DIBENEDETTO'), ('1/validation_v2/validation/VALIDATION_0022.jpg', 'MATHIS'), ('1/validation_v2/validation/VALIDATION_0023.jpg', 'LOUNA'), ('1/validation_v2/validation/VALIDATION_0024.jpg', 'SEVESTRE'), ('1/validation_v2/validation/VALIDATION_0025.jpg', 'DAVANLAY'), ('1/validation_v2/validation/VALIDATION_0026.jpg', 'HOCQUARD'), ('1/validation_v2/validation/VALIDATION_0027.jpg', 'LEBRUN'), ('1/validation_v2/validation/VALIDATION_0028.jpg', 'DABIN'), ('1/validation_v2/validation/VALIDATION_0029.jpg', 'SENDOUBI'), ('1/validation_v2/validation/VALIDATION_0030.jpg', 'DI PASQUALE'), ('1/validation_v2/validation/VALIDATION_0031.jpg', 'PRIVAT'), ('1/validation_v2/validation/VALIDATION_0032.jpg', 'HUGO'), ('1/validation_v2/validation/VALIDATION_0033.jpg', 'MAONI'), ('1/validation_v2/validation/VALIDATION_0034.jpg', 'COTTIGNY'), ('1/validation_v2/validation/VALIDATION_0035.jpg', 'SARRAZIN'), ('1/validation_v2/validation/VALIDATION_0036.jpg', 'FRERE'), ('1/validation_v2/validation/VALIDATION_0037.jpg', 'MONSOH'), ('1/validation_v2/validation/VALIDATION_0038.jpg', 'BELMERROUBICARRO'), ('1/validation_v2/validation/VALIDATION_0039.jpg', 'CLEMENT'), ('1/validation_v2/validation/VALIDATION_0040.jpg', 'ALLEMBRAND'), ('1/validation_v2/validation/VALIDATION_0041.jpg', 'CASSANORA'), ('1/validation_v2/validation/VALIDATION_0042.jpg', 'VIEILLE'), ('1/validation_v2/validation/VALIDATION_0043.jpg', 'VAUTIER'), ('1/validation_v2/validation/VALIDATION_0044.jpg', 'LOUISE'), ('1/validation_v2/validation/VALIDATION_0045.jpg', 'DUTARR ICR'), ('1/validation_v2/validation/VALIDATION_0046.jpg', 'ENNIO'), ('1/validation_v2/validation/VALIDATION_0047.jpg', 'ALYSSIA'), ('1/validation_v2/validation/VALIDATION_0048.jpg', 'RUIZ'), ('1/validation_v2/validation/VALIDATION_0049.jpg', 'LIZANA'), ('1/validation_v2/validation/VALIDATION_0050.jpg', 'CAMILLE'), ('1/validation_v2/validation/VALIDATION_0051.jpg', 'JULIE'), ('1/validation_v2/validation/VALIDATION_0052.jpg', 'ELIA'), ('1/validation_v2/validation/VALIDATION_0053.jpg', 'AXEL'), ('1/validation_v2/validation/VALIDATION_0054.jpg', 'ANTOINE'), ('1/validation_v2/validation/VALIDATION_0055.jpg', 'NION'), ('1/validation_v2/validation/VALIDATION_0056.jpg', 'RICHARD'), ('1/validation_v2/validation/VALIDATION_0057.jpg', 'COONAC'), ('1/validation_v2/validation/VALIDATION_0058.jpg', 'DAVOULT'), ('1/validation_v2/validation/VALIDATION_0059.jpg', 'SAAD'), ('1/validation_v2/validation/VALIDATION_0060.jpg', 'DUBOIS'), ('1/validation_v2/validation/VALIDATION_0061.jpg', 'NAU'), ('1/validation_v2/validation/VALIDATION_0062.jpg', 'JULIEN'), ('1/validation_v2/validation/VALIDATION_0063.jpg', 'BENET'), ('1/validation_v2/validation/VALIDATION_0064.jpg', 'DAVID'), ('1/validation_v2/validation/VALIDATION_0065.jpg', 'THOMAS'), ('1/validation_v2/validation/VALIDATION_0066.jpg', 'VAILLANT'), ('1/validation_v2/validation/VALIDATION_0067.jpg', 'JOAO'), ('1/validation_v2/validation/VALIDATION_0068.jpg', 'LYLOU'), ('1/validation_v2/validation/VALIDATION_0069.jpg', 'CARA'), ('1/validation_v2/validation/VALIDATION_0070.jpg', 'TABUT'), ('1/validation_v2/validation/VALIDATION_0071.jpg', 'PELLETIER'), ('1/validation_v2/validation/VALIDATION_0072.jpg', 'AUTRET'), ('1/validation_v2/validation/VALIDATION_0073.jpg', 'CHECROUN'), ('1/validation_v2/validation/VALIDATION_0074.jpg', 'VASSEUR'), ('1/validation_v2/validation/VALIDATION_0075.jpg', 'FAURE'), ('1/validation_v2/validation/VALIDATION_0076.jpg', 'EMMA'), ('1/validation_v2/validation/VALIDATION_0077.jpg', 'ARTHUR'), ('1/validation_v2/validation/VALIDATION_0078.jpg', 'FRIMIN'), ('1/validation_v2/validation/VALIDATION_0079.jpg', 'ANAELLE'), ('1/validation_v2/validation/VALIDATION_0080.jpg', 'DYEAN'), ('1/validation_v2/validation/VALIDATION_0081.jpg', 'RAPHEL'), ('1/validation_v2/validation/VALIDATION_0082.jpg', 'VANTOMME'), ('1/validation_v2/validation/VALIDATION_0083.jpg', 'OMNES'), ('1/validation_v2/validation/VALIDATION_0084.jpg', 'ANTOINE'), ('1/validation_v2/validation/VALIDATION_0085.jpg', 'ANDRANIK'), ('1/validation_v2/validation/VALIDATION_0086.jpg', 'LUCAS'), ('1/validation_v2/validation/VALIDATION_0087.jpg', 'CELIA'), ('1/validation_v2/validation/VALIDATION_0088.jpg', 'LOURENCO'), ('1/validation_v2/validation/VALIDATION_0089.jpg', 'MAYLIS'), ('1/validation_v2/validation/VALIDATION_0090.jpg', 'LUCIE'), ('1/validation_v2/validation/VALIDATION_0091.jpg', 'DEBARD'), ('1/validation_v2/validation/VALIDATION_0092.jpg', 'DEPAQUY'), ('1/validation_v2/validation/VALIDATION_0093.jpg', 'VERHILLE'), ('1/validation_v2/validation/VALIDATION_0094.jpg', 'SORRESE'), ('1/validation_v2/validation/VALIDATION_0095.jpg', 'HUGO'), ('1/validation_v2/validation/VALIDATION_0096.jpg', 'CRUSSIERE'), ('1/validation_v2/validation/VALIDATION_0097.jpg', 'THEANA'), ('1/validation_v2/validation/VALIDATION_0098.jpg', 'LEDROLE'), ('1/validation_v2/validation/VALIDATION_0099.jpg', 'BERNARD'), ('1/validation_v2/validation/VALIDATION_0100.jpg', 'VALENTINE'), ('1/validation_v2/validation/VALIDATION_0101.jpg', 'GABRIELLE'), ('1/validation_v2/validation/VALIDATION_0102.jpg', 'CLOE'), ('1/validation_v2/validation/VALIDATION_0103.jpg', 'BONNE'), ('1/validation_v2/validation/VALIDATION_0104.jpg', 'ELGUOFA'), ('1/validation_v2/validation/VALIDATION_0105.jpg', 'MORGANE'), ('1/validation_v2/validation/VALIDATION_0106.jpg', 'ROZENN'), ('1/validation_v2/validation/VALIDATION_0107.jpg', 'DYLAN'), ('1/validation_v2/validation/VALIDATION_0108.jpg', 'ANTHONY'), ('1/validation_v2/validation/VALIDATION_0109.jpg', 'LEA'), ('1/validation_v2/validation/VALIDATION_0110.jpg', 'WALID'), ('1/validation_v2/validation/VALIDATION_0111.jpg', 'HEDDEBAUX'), ('1/validation_v2/validation/VALIDATION_0112.jpg', 'LUCAS'), ('1/validation_v2/validation/VALIDATION_0113.jpg', 'TEO'), ('1/validation_v2/validation/VALIDATION_0114.jpg', 'DEMEESTERE'), ('1/validation_v2/validation/VALIDATION_0115.jpg', 'CAGGANDRO'), ('1/validation_v2/validation/VALIDATION_0116.jpg', 'CHIO'), ('1/validation_v2/validation/VALIDATION_0117.jpg', 'DO ROSARIO'), ('1/validation_v2/validation/VALIDATION_0118.jpg', 'JAHIER'), ('1/validation_v2/validation/VALIDATION_0119.jpg', 'DIANA'), ('1/validation_v2/validation/VALIDATION_0120.jpg', 'FRENOT'), ('1/validation_v2/validation/VALIDATION_0121.jpg', 'VIDAL'), ('1/validation_v2/validation/VALIDATION_0122.jpg', 'COMBE'), ('1/validation_v2/validation/VALIDATION_0123.jpg', 'PERITO'), ('1/validation_v2/validation/VALIDATION_0124.jpg', 'CHIPRET'), ('1/validation_v2/validation/VALIDATION_0125.jpg', 'CAMPOLO'), ('1/validation_v2/validation/VALIDATION_0126.jpg', 'EL FETOUVAKI'), ('1/validation_v2/validation/VALIDATION_0127.jpg', 'JUSTIN'), ('1/validation_v2/validation/VALIDATION_0128.jpg', 'SPLENE'), ('1/validation_v2/validation/VALIDATION_0129.jpg', 'GEHAN'), ('1/validation_v2/validation/VALIDATION_0130.jpg', 'LOU-ANNE'), ('1/validation_v2/validation/VALIDATION_0131.jpg', 'LEITAO PEREIRA'), ('1/validation_v2/validation/VALIDATION_0132.jpg', 'AXEL'), ('1/validation_v2/validation/VALIDATION_0133.jpg', 'HOUDOT-HERRING'), ('1/validation_v2/validation/VALIDATION_0134.jpg', 'ASNARD'), ('1/validation_v2/validation/VALIDATION_0135.jpg', 'MASSINE'), ('1/validation_v2/validation/VALIDATION_0136.jpg', 'NOE'), ('1/validation_v2/validation/VALIDATION_0137.jpg', 'SALLOT'), ('1/validation_v2/validation/VALIDATION_0138.jpg', 'SIDIKI'), ('1/validation_v2/validation/VALIDATION_0139.jpg', 'CLEMENCE'), ('1/validation_v2/validation/VALIDATION_0140.jpg', 'ELYCIA'), ('1/validation_v2/validation/VALIDATION_0141.jpg', 'LISA'), ('1/validation_v2/validation/VALIDATION_0142.jpg', 'LE CAM'), ('1/validation_v2/validation/VALIDATION_0143.jpg', 'GOLGOLAB'), ('1/validation_v2/validation/VALIDATION_0144.jpg', 'BRICE'), ('1/validation_v2/validation/VALIDATION_0145.jpg', 'RANBAUD'), ('1/validation_v2/validation/VALIDATION_0146.jpg', 'ROMANE'), ('1/validation_v2/validation/VALIDATION_0147.jpg', 'GELOEN'), ('1/validation_v2/validation/VALIDATION_0148.jpg', 'NINE'), ('1/validation_v2/validation/VALIDATION_0149.jpg', 'MAHE'), ('1/validation_v2/validation/VALIDATION_0150.jpg', 'MAYRA'), ('1/validation_v2/validation/VALIDATION_0151.jpg', 'PIGA'), ('1/validation_v2/validation/VALIDATION_0152.jpg', 'CACHOT'), ('1/validation_v2/validation/VALIDATION_0153.jpg', 'ABDELKARIM'), ('1/validation_v2/validation/VALIDATION_0154.jpg', 'GENDRON'), ('1/validation_v2/validation/VALIDATION_0155.jpg', 'CASSIOPEE'), ('1/validation_v2/validation/VALIDATION_0156.jpg', 'ROBIN'), ('1/validation_v2/validation/VALIDATION_0157.jpg', 'MANON'), ('1/validation_v2/validation/VALIDATION_0158.jpg', 'TIMOTHEE'), ('1/validation_v2/validation/VALIDATION_0159.jpg', 'LEMARIE'), ('1/validation_v2/validation/VALIDATION_0160.jpg', 'OLIVIER'), ('1/validation_v2/validation/VALIDATION_0161.jpg', 'BOUBTANA'), ('1/validation_v2/validation/VALIDATION_0162.jpg', 'PIERRE'), ('1/validation_v2/validation/VALIDATION_0163.jpg', 'SOPHIE'), ('1/validation_v2/validation/VALIDATION_0164.jpg', 'FONSECA'), ('1/validation_v2/validation/VALIDATION_0165.jpg', 'LUCZKOW'), ('1/validation_v2/validation/VALIDATION_0166.jpg', 'ALYSON'), ('1/validation_v2/validation/VALIDATION_0167.jpg', 'PAMELA'), ('1/validation_v2/validation/VALIDATION_0168.jpg', 'COLOVIC'), ('1/validation_v2/validation/VALIDATION_0169.jpg', 'VOINCHET'), ('1/validation_v2/validation/VALIDATION_0170.jpg', 'KAWTAR'), ('1/validation_v2/validation/VALIDATION_0171.jpg', 'BINAULT'), ('1/validation_v2/validation/VALIDATION_0172.jpg', 'BAKOUR'), ('1/validation_v2/validation/VALIDATION_0173.jpg', 'FOLIARD'), ('1/validation_v2/validation/VALIDATION_0174.jpg', 'LECOMTE'), ('1/validation_v2/validation/VALIDATION_0175.jpg', 'BUSIN'), ('1/validation_v2/validation/VALIDATION_0176.jpg', 'PARRET'), ('1/validation_v2/validation/VALIDATION_0177.jpg', 'MADELINE'), ('1/validation_v2/validation/VALIDATION_0178.jpg', 'NOT'), ('1/validation_v2/validation/VALIDATION_0179.jpg', 'GUENOLE'), ('1/validation_v2/validation/VALIDATION_0180.jpg', 'EMPTY'), ('1/validation_v2/validation/VALIDATION_0181.jpg', 'JOBIN'), ('1/validation_v2/validation/VALIDATION_0182.jpg', 'BUTEZ'), ('1/validation_v2/validation/VALIDATION_0183.jpg', 'LOUIS-AUXENCE'), ('1/validation_v2/validation/VALIDATION_0184.jpg', 'SIXTINE'), ('1/validation_v2/validation/VALIDATION_0185.jpg', 'GAMBIER'), ('1/validation_v2/validation/VALIDATION_0186.jpg', 'ELHADI'), ('1/validation_v2/validation/VALIDATION_0187.jpg', 'CYRIL'), ('1/validation_v2/validation/VALIDATION_0188.jpg', 'EMMA'), ('1/validation_v2/validation/VALIDATION_0189.jpg', 'GAUTIER'), ('1/validation_v2/validation/VALIDATION_0190.jpg', 'DEL PRETE'), ('1/validation_v2/validation/VALIDATION_0191.jpg', 'CLARA'), ('1/validation_v2/validation/VALIDATION_0192.jpg', 'BLONDEAU'), ('1/validation_v2/validation/VALIDATION_0193.jpg', 'SOEZIC MARIE'), ('1/validation_v2/validation/VALIDATION_0194.jpg', 'NDIAA'), ('1/validation_v2/validation/VALIDATION_0195.jpg', 'MATTEO'), ('1/validation_v2/validation/VALIDATION_0196.jpg', 'ADRIEN'), ('1/validation_v2/validation/VALIDATION_0197.jpg', 'ILYAS'), ('1/validation_v2/validation/VALIDATION_0198.jpg', 'TRUMEAU'), ('1/validation_v2/validation/VALIDATION_0199.jpg', 'PONTVERT-DELUCQ'), ('1/validation_v2/validation/VALIDATION_0200.jpg', 'JIM'), ('1/validation_v2/validation/VALIDATION_0201.jpg', 'CAKIR')]\n",
      "[('1/test_v2/test/TEST_0001.jpg', 'KEVIN'), ('1/test_v2/test/TEST_0002.jpg', 'CLOTAIRE'), ('1/test_v2/test/TEST_0003.jpg', 'LENA'), ('1/test_v2/test/TEST_0004.jpg', 'JULES'), ('1/test_v2/test/TEST_0005.jpg', 'CHERPIN'), ('1/test_v2/test/TEST_0006.jpg', 'MARTIN'), ('1/test_v2/test/TEST_0007.jpg', 'VALENTINE'), ('1/test_v2/test/TEST_0008.jpg', 'LORAS'), ('1/test_v2/test/TEST_0009.jpg', 'THIBAULT'), ('1/test_v2/test/TEST_0010.jpg', 'AZABI'), ('1/test_v2/test/TEST_0011.jpg', 'GORTCHAKOFF'), ('1/test_v2/test/TEST_0012.jpg', 'MAHENTHIRAN'), ('1/test_v2/test/TEST_0013.jpg', 'FRANSOISSISEPH'), ('1/test_v2/test/TEST_0014.jpg', 'JEANNE'), ('1/test_v2/test/TEST_0015.jpg', 'DEBORAH'), ('1/test_v2/test/TEST_0016.jpg', 'DROUCS'), ('1/test_v2/test/TEST_0017.jpg', 'JADE'), ('1/test_v2/test/TEST_0018.jpg', 'CORNIL FRERROT'), ('1/test_v2/test/TEST_0019.jpg', 'CLEMET'), ('1/test_v2/test/TEST_0020.jpg', 'RELIS'), ('1/test_v2/test/TEST_0021.jpg', 'NAMIZATA FATIM'), ('1/test_v2/test/TEST_0022.jpg', 'FOURNEL'), ('1/test_v2/test/TEST_0023.jpg', 'DICINTIO-ILLESCA'), ('1/test_v2/test/TEST_0024.jpg', 'BARDOT'), ('1/test_v2/test/TEST_0025.jpg', 'DUVAL'), ('1/test_v2/test/TEST_0026.jpg', 'ANTONY'), ('1/test_v2/test/TEST_0027.jpg', 'LISA'), ('1/test_v2/test/TEST_0028.jpg', 'CELIA'), ('1/test_v2/test/TEST_0029.jpg', 'GRODZKI'), ('1/test_v2/test/TEST_0030.jpg', 'HUGO'), ('1/test_v2/test/TEST_0031.jpg', 'HUGO'), ('1/test_v2/test/TEST_0032.jpg', 'ELOUEN'), ('1/test_v2/test/TEST_0033.jpg', 'SCHOEMAECKER'), ('1/test_v2/test/TEST_0034.jpg', 'HOARAU'), ('1/test_v2/test/TEST_0035.jpg', 'STEENKERSTE'), ('1/test_v2/test/TEST_0036.jpg', 'DI -FONZO'), ('1/test_v2/test/TEST_0037.jpg', 'BUIREY'), ('1/test_v2/test/TEST_0038.jpg', 'ROMAN'), ('1/test_v2/test/TEST_0039.jpg', 'MILLE'), ('1/test_v2/test/TEST_0040.jpg', 'CAROLINE'), ('1/test_v2/test/TEST_0041.jpg', 'PAUL'), ('1/test_v2/test/TEST_0042.jpg', 'BECHARA'), ('1/test_v2/test/TEST_0043.jpg', 'DIBOS'), ('1/test_v2/test/TEST_0044.jpg', 'JEAN COME'), ('1/test_v2/test/TEST_0045.jpg', 'DRENIN'), ('1/test_v2/test/TEST_0046.jpg', 'CLOUIS'), ('1/test_v2/test/TEST_0047.jpg', 'JORIS'), ('1/test_v2/test/TEST_0048.jpg', 'NARDINI'), ('1/test_v2/test/TEST_0049.jpg', 'CLAIRE'), ('1/test_v2/test/TEST_0050.jpg', 'RAFFORT')]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "def create_keras_ocr_dataset(image_dir, df, limit, image_col='FILENAME', text_col='IDENTITY'):\n",
    "    \"\"\"\n",
    "    Create a keras-ocr dataset from a directory of images and a DataFrame.\n",
    "    \n",
    "    Args:\n",
    "        image_dir (str): Path to directory containing images\n",
    "        df (pd.DataFrame): DataFrame containing image filenames and corresponding text\n",
    "        image_col (str): Column name in df containing image filenames\n",
    "        text_col (str): Column name in df containing text labels\n",
    "    \n",
    "    Returns:\n",
    "        list: List of tuples in format [(image_path, text), ...]\n",
    "    \"\"\"\n",
    "    dataset = []\n",
    "    count = 0\n",
    "    for _, row in df.iterrows():\n",
    "        if count == limit:\n",
    "            break\n",
    "        image_path = image_dir+\"/\"+ row[image_col]\n",
    "        if os.path.exists(image_path):\n",
    "            dataset.append((image_path, row[text_col]))\n",
    "        else:\n",
    "            print(f\"Warning: Image not found at {image_path}\")\n",
    "        count +=1\n",
    "    return dataset\n",
    "\n",
    "train_dataset = create_keras_ocr_dataset( '1/train_v2/train',train, 800)\n",
    "validation_dataset = create_keras_ocr_dataset( '1/validation_v2/validation',valid, 200)\n",
    "test_datasset = create_keras_ocr_dataset('1/test_v2/test', test, 50)\n",
    "print(train_dataset)\n",
    "print(validation_dataset)\n",
    "print(test_datasset)\n",
    "\n",
    "import tensorflow as tf\n",
    "def loadTrainData(dataSetList, imageSize=(200, 31)):\n",
    "    images = []\n",
    "    texts = []\n",
    "    for (path,text)in dataSetList:\n",
    "        img = cv2.imread(path)  # Load image using OpenCV\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)  # Convert BGR to RGB\n",
    "        #COULD RESIZE\n",
    "        img = cv2.resize(img, imageSize)#MAYBE ROTATE IMAGE AND THEN HAVE LENGTH AND WIDTH FLIPPED\n",
    "\n",
    "        img = img/255.0\n",
    "        #img = img.astype(np.float32) / 255.0  # Normalize pixel values to [0,1]\n",
    "        #img = tf.convert_to_tensor(img, dtype=tf.float32)  # Convert to TensorFlow tensor\n",
    "        images.append(img)\n",
    "        texts.append(text)\n",
    "    return np.array(images), texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of imagesTrain: (800, 31, 200, 1)\n",
      "Shape of imagesVal: (200, 31, 200, 1)\n",
      "Shape of imagesTest: (1, 31, 200, 1)\n",
      "Shape of train_inputs: <class 'numpy.ndarray'>\n",
      "Epoch 1/3\n",
      "25/25 [==============================] - 294s 11s/step - loss: 0.7023 - val_loss: 43.7442\n",
      "Epoch 2/3\n",
      "25/25 [==============================] - 285s 11s/step - loss: 0.3374 - val_loss: 45.6239\n",
      "Epoch 3/3\n",
      "25/25 [==============================] - 275s 11s/step - loss: 0.2101 - val_loss: 45.7859\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.layers import Input, Lambda\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "# CTC loss function\n",
    "def ctc_loss_lambda_func(args):\n",
    "    y_pred, labels, input_length, label_length = args\n",
    "    return K.ctc_batch_cost(labels, y_pred, input_length, label_length)\n",
    "\n",
    "# Create the CTC model\n",
    "def create_ctc_model(base_model, input_shape):\n",
    "    # Input for images\n",
    "    input_img = Input(shape=input_shape, name='input_data')\n",
    "    \n",
    "    # Inputs for CTC loss\n",
    "    labels = Input(name='labels', shape=[None], dtype='int32')\n",
    "    input_length = Input(name='input_length', shape=[1], dtype='int32')\n",
    "    label_length = Input(name='label_length', shape=[1], dtype='int32')\n",
    "    \n",
    "    # Get the output from the base model\n",
    "    base_output = base_model(input_img)\n",
    "    \n",
    "    # Add a Lambda layer for CTC loss\n",
    "    loss_out = Lambda(ctc_loss_lambda_func, output_shape=(1,), name='ctc')(\n",
    "        [base_output, labels, input_length, label_length]\n",
    "    )\n",
    "    \n",
    "    # Create the full model\n",
    "    model = Model(\n",
    "        inputs=[input_img, labels, input_length, label_length],\n",
    "        outputs=loss_out\n",
    "    )\n",
    "    return model\n",
    "\n",
    "# Convert text to integer sequences\n",
    "def textToNum(texts):\n",
    "    tokenizer = Tokenizer(char_level=True)  # Character-level encoding\n",
    "    tokenizer.fit_on_texts(texts)\n",
    "\n",
    "    # Convert text to integer sequences\n",
    "    texts_encoded = tokenizer.texts_to_sequences(texts)\n",
    "\n",
    "    # Pad sequences (if necessary for your model)\n",
    "    texts_encoded = pad_sequences(texts_encoded, maxlen=48, padding='post')\n",
    "\n",
    "    # Return integer-encoded labels (no one-hot encoding for CTC loss)\n",
    "    return texts_encoded\n",
    "\n",
    "# Prepare data for CTC loss\n",
    "def prepare_data_for_ctc(images, texts_encoded):\n",
    "    # Get the sequence length from the model's output shape\n",
    "    feature_map_shape = model.output_shape\n",
    "    sequence_length = feature_map_shape[1]  # The width of the feature map after downsampling\n",
    "\n",
    "    # Input length is the sequence length\n",
    "    input_length = np.ones((len(images), 1)) * sequence_length\n",
    "\n",
    "    # Label length is the actual length of each label (ignoring padding)\n",
    "    label_length = np.array([[len(text[text > 0])] for text in texts_encoded])\n",
    "\n",
    "    return {\n",
    "        'input_data': images,\n",
    "        'labels': texts_encoded,\n",
    "        'input_length': input_length,\n",
    "        'label_length': label_length\n",
    "    }\n",
    "\n",
    "# Load data\n",
    "imagesTrain, textsTrain = loadTrainData(train_dataset)\n",
    "imagesVal, textVal = loadTrainData(validation_dataset)\n",
    "imagesTest, testText = loadTrainData(test_dataset)\n",
    "\n",
    "# Add channel dimension (for grayscale images)\n",
    "imagesTrain = np.expand_dims(imagesTrain, axis=-1)  # Add channel dimension\n",
    "imagesVal = np.expand_dims(imagesVal, axis=-1)\n",
    "imagesTest = np.expand_dims(imagesTest, axis=-1)\n",
    "\n",
    "# Debugging: Print shapes to verify\n",
    "print(f\"Shape of imagesTrain: {imagesTrain.shape}\")  # Should be (num_samples, height, width, 1)\n",
    "print(f\"Shape of imagesVal: {imagesVal.shape}\")\n",
    "print(f\"Shape of imagesTest: {imagesTest.shape}\")\n",
    "\n",
    "\n",
    "# Prepare the data\n",
    "textsTrain_encoded = textToNum(textsTrain)\n",
    "textVal_encoded = textToNum(textVal)\n",
    "\n",
    "train_inputs = prepare_data_for_ctc(imagesTrain, textsTrain_encoded)\n",
    "val_inputs = prepare_data_for_ctc(imagesVal, textVal_encoded)\n",
    "\n",
    "# Dummy outputs for CTC loss\n",
    "train_outputs = np.zeros((len(imagesTrain), 1))\n",
    "val_outputs = np.zeros((len(imagesVal), 1))\n",
    "\n",
    "\n",
    "print(f\"Shape of train_inputs: {type(imagesTrain)}\")  # (number_of_samples, height, width, channels)\n",
    "\n",
    "# Create the custom CTC model\n",
    "input_shape = (imagesTrain.shape[1], imagesTrain.shape[2], imagesTrain.shape[3])  # (height, width, channels)\n",
    "recognizer.model.layers[-1].activation = tf.keras.activations.softmax  #last layer has softmax activation\n",
    "ctc_model = create_ctc_model(recognizer.model, input_shape)\n",
    "\n",
    "# Compile the model with a dummy loss\n",
    "ctc_model.compile(optimizer='adam', loss={'ctc': lambda y_true, y_pred: y_pred})\n",
    "\n",
    "# Train the model\n",
    "newModel = ctc_model.fit(\n",
    "    x=[train_inputs['input_data'], \n",
    "       train_inputs['labels'],\n",
    "       train_inputs['input_length'],\n",
    "       train_inputs['label_length']],\n",
    "    y=train_outputs,\n",
    "    validation_data=(\n",
    "        [val_inputs['input_data'],\n",
    "         val_inputs['labels'],\n",
    "         val_inputs['input_length'],\n",
    "         val_inputs['label_length']],\n",
    "        val_outputs\n",
    "    ),\n",
    "    epochs=3,       # try on 2\n",
    "    batch_size=32 # try on 8\n",
    ")\n",
    "\n",
    "# Save the trained model\n",
    "ctc_model.save('kerasTrained.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 244ms/step\n",
      "Predicted text: ['k e e i n']\n",
      "Test Sample 1:\n",
      "  Predicted: k e e i n\n",
      "  Actual:    {'lines': [{'text': 'KEVIN', 'vertices': [(25, 6), (91, 6), (91, 22), (25, 22)]}]}\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "prediction = model.predict(imagesTest)\n",
    "# If it's a classification problem, you can get the predicted class\n",
    "predicted_class = np.argmax(prediction, axis=-1)\n",
    "\n",
    "# If it's an OCR problem, you might need to decode the result (assuming your model outputs text)\n",
    "decoded_text = tokenizer.sequences_to_texts(predicted_class)\n",
    "print(f\"Predicted text: {decoded_text}\")\n",
    "\n",
    "\n",
    "for i, (pred, true) in enumerate(zip(decoded_text, testText)):\n",
    "    print(f\"Test Sample {i+1}:\")\n",
    "    print(f\"  Predicted: {pred}\")\n",
    "    print(f\"  Actual:    {true}\")\n",
    "    print(\"-\" * 30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Past Idea (didnt work since error function and how text is encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import tensorflow as tf\n",
    "#import os\n",
    "#\n",
    "#from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "#from tensorflow.keras.utils import to_categorical\n",
    "#import numpy as np\n",
    "#\n",
    "#def textToNum(texts):\n",
    "#    numberClasses = 37 #from errors of sizes\n",
    "#\n",
    "#    # Step 1: Tokenizer (character-level encoding)\n",
    "#    tokenizer = Tokenizer(char_level=True)  # Character-level encoding\n",
    "#    tokenizer.fit_on_texts(texts)\n",
    "#\n",
    "#    # Step 2: Convert text to integer sequences\n",
    "#    textsTrain_encoded = tokenizer.texts_to_sequences(texts)\n",
    "#\n",
    "#    # Step 3: Pad sequences (if necessary for your model)\n",
    "#    from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "#    textsTrain_encoded = pad_sequences(textsTrain_encoded, maxlen=48, padding='post')\n",
    "#\n",
    "#    # Step 4: One-hot encode if using categorical crossentropy\n",
    "#    textsTrain_encoded = to_categorical(textsTrain_encoded, num_classes=numberClasses)\n",
    "#    return textsTrain_encoded\n",
    "#\n",
    "#def ctc_loss(y_true, y_pred):\n",
    "#    return K.ctc_batch_cost(y_true, y_pred, input_length=K.ones_like(y_pred[:, 0, 0]) * K.shape(y_pred)[1], label_length=K.ones_like(y_true[:, 0]) * K.shape(y_true)[1])\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#imagesTrain, textsTrain =loadTrainData(train_dataset)\n",
    "#imagesVal, textVal = loadTrainData(validation_dataset)\n",
    "#imagesTest, testText = loadTrainData(test_dataset)\n",
    "#\n",
    "#textVal_encoded = textToNum(textVal)\n",
    "#textsTrain_encoded = textToNum(textsTrain)\n",
    "#\n",
    "#batch_size = 8\n",
    "#\n",
    "#\n",
    "#print(f\"Shape of imagesTrain: {imagesTrain.shape}\")  # (number_of_samples, height, width, channels)\n",
    "#print(f\"Shape of textsTrain_encoded: {textsTrain_encoded.shape}\")  # (number_of_samples, max_sequence_length)\n",
    "#\n",
    "#\n",
    "#print(f\"Shape of imagesVal: {imagesVal.shape}\")  # (number_of_samples, height, width, channels)\n",
    "#print(f\"Shape of textsVal_encoded: {textVal_encoded.shape}\")  # (number_of_samples, max_sequence_length)\n",
    "#\n",
    "#\n",
    "#assert imagesTrain.shape[0] == textsTrain_encoded.shape[0], \"Mismatch in number of samples between images and labels\"\n",
    "#assert imagesVal.shape[0] == textVal_encoded.shape[0], \"Mismatch in number of validation samples\"\n",
    "#\n",
    "#\n",
    "#recognizer = keras_ocr.recognition.Recognizer()\n",
    "#model = recognizer.model\n",
    "#\n",
    "#model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "#\n",
    "#newModel = model.fit(\n",
    "#    x=imagesTrain,\n",
    "#    y = textsTrain_encoded,#I Think\n",
    "#    validation_data=(imagesVal, textVal_encoded),\n",
    "#    epochs=10,\n",
    "#    batch_size=batch_size\n",
    "#)\n",
    "#\n",
    "#model.save('kerasTrained.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
